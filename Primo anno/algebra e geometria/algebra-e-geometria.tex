\documentclass{book}
\usepackage[a4paper,top=2.0cm,bottom=2.0cm,left=3.0cm,right=3.0cm]{geometry}

%\documentclass[pdftex,10pt,a4paper]{book}
%\usepackage[paperwidth=19cm,
%paperheight=26cm, outer=2cm, 
%top=1.5cm, bottom=1.5cm]{ geometry}

\usepackage[english,italian]{babel} %l'ultima lingua è quella che legge per i titoli
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc,url}
\usepackage{titlesec}
\usepackage{easylist}
\usepackage{hanging}

\usepackage[pdftex,colorlinks]{hyperref}
\hypersetup{
	colorlinks=true,
	linkcolor=black,
	filecolor=magenta,
	urlcolor=cyan,
}
\usepackage{hypcap}
\usepackage{blindtext}
\usepackage{tipa}
\usepackage{epigraph}
\usepackage{enumerate}
\usepackage{longtable}
\usepackage{setspace}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{pbox}
\usepackage{fancyhdr}
\usepackage{cancel}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{tikz}
\usepackage{tikz-qtree}
\usepackage{subfig}
\usepackage{xcolor}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{textcomp}
\usepackage{circuitikz}
\usepackage{pifont}
\usepackage{imakeidx}
\usepackage{verbatim}
\usepackage{dsfont}
\usepackage{listings}
\usepackage{color}
\usepackage{upgreek}
\usepackage{tasks}
\usepackage{exsheets}
\usepackage{pgfplots}
\usepackage{amsthm}
\usepackage{wasysym}
\usepackage{dsfont}
\usepackage{thmtools}

% impostazioni grafici
\usepackage{tikzit}
\input{img/stile.tikzstyles}

\usepackage{showframe}
\renewcommand\ShowFrameLinethickness{0.15pt}
%\renewcommand*\ShowFrameColor{\color{red}}

%\usepackage{showkeys} %serve per mostrare le etichette "tag" o target, va tolta per la versione definitiva;

\SetupExSheets[question]{type=exam}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{ 
  backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}; should come as last argument
  basicstyle=\footnotesize,        % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  deletekeywords={...},            % if you want to delete keywords from the given language
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  firstnumber=1000,                % start line enumeration with line 1000
  frame=single,	                   % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  language=Octave,                 % the language of the code
  morekeywords={*,...},            % if you want to add more keywords to the set
  numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=2,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{mymauve},     % string literal style
  tabsize=2,	                   % sets default tabsize to 2 spaces
  title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
}

\frenchspacing

\newcommand{\abs}[1]{\lvert#1\rvert}

\usepackage{floatflt,epsfig}

\usepackage{multicol}
\newcommand\yellowbigsqcup[1][\displaystyle]{%
  \fboxrule0pt
  \ifx#1\textstyle\fboxsep-0.6pt\else\fboxsep-1.25pt\fi
  \mathrel{\fcolorbox{white}{yellow}{$#1\bigsqcup$}}}

\theoremstyle{definition}
\newtheorem{defi}{Definizione}[section]
\newtheorem{es}{Esempio}[section]
\newtheorem{teo}{Teorema}[section]
\newtheorem{oss}{Osservazione}[section]
\theoremstyle{plain}
\newtheorem{nota}{Nota}[section]
\newtheorem{prop}{Proposizione}[section]
\newtheorem{pro}{Proprietà}[section]

\title{Algebra e geometria}
\author{Nicola Ferru}
\begin{document}
\maketitle
\tableofcontents

\subsubsection{Prefazione}
\label{sec:pref}
Le modalità di utilizzo e distribuzione sono scritte nel file \href{https://github.com/NF02/Appunti-universita/blob/main/LICENSE}{LICENSE}.
\input{pag/vettcoordegeo.tex}

\chapter{Sistemi di equazioni lineari e matrici}
\label{chap:eqlinematrici}

Per definire rigorosamente cosa si intenda per equazione lineare
(o equazione di $1^o$ grado) e scrivere il generico esempio di
equazione lineare, si trova prima una notazione conveniente per
denotare tali equazioni.\\
Infatti, per non avere limitazioni sul numero delle incognite,
non è possibile continuare a indicarle con le lettere
dell'alfabeto $x,y,z,etc.$, che sono in numero limitato, ma
verrà utilizzata sempre la stessa lettera, tradizionalmente
la $x$ con degli indicatori numerici che consentono di
quale incognita si tratta: $x_1,x_2,\dots,x_n$ con, dove $n$ è
un numero naturale. Facendo un esempio di strutturate in questo
modo, si otterrà una situazione di questo tipo
\begin{equation}
  \label{eq:eqlinematrici1}
  a_1x_1+a_2x_2+\cdots+a_nx_n=b
\end{equation}
dove $b,a_1,a_2,\dots,a_n$ sono elementi di un campo
(solitamente, il campo dei numeri reali o quello dei complessi)
che svolgono il ruolo rispettivamente di termine noto e
coefficienti delle incognite (per ogni incognita $x_i$, bisogna
denotare il suo coefficiente con una lettera, $a_i$ con lo stesso
indice dell'incognita).\\
Dare una soluzione dell'equazione (\ref{eq:eqlinematrici1})
significa trovare degli elementi del campo, ovvero dei numeri,
che sostituiti alle incognite rendano l'ugualianza vera.\\
Ad esempio, nell'equazione lineare in due incognite $x_1-x_2=1$
a coefficienti nel campo dei reali $\mathds{R}$, ponendo $x_1=2$
e $x_2=1$ si ottiene l'ugualianza vera $2-1=1$, mentre ad esempio
ponendo $x_1=1$ e $x_2=2$ si ottiene $1-2=1$ che è falsa.\\
Da questo semplice esempio si vede come dare una soluzione
dell'equazione $x_1-x_2=1$ significa non solo dare \textit{due}
valori numerici, da sostituire alle due incognite
dell'equazione, ma è necessario precisare quale valore vada
sostituito alla prima incognita e quale alla seconda, ovvero
specificare in quale ordine stiamo prendendo questi due
elementi.

La soluzione data di tale equazione può essere pensata e scritta
come una \textit{coppia ordinata} di numeri, che è possibile
denotare in (\ref{eq:eqlinematrici1}). La coppia (2,1) è una
soluzione dell'equazione $x_1-x_2=1$, mentre la caoppia (1,2) non
lo è.\\
Analogamente, per un'equazione con 3 incognite, una sua
soluzione sarà data da una terna ordinata (3,2,1) è una sua
soluzione, in quanto sostituendo $x_1=3,x_2=2,x_3=1$ si ottiene
l'uguaglianza vera $3-2+1=2$; la terna (2,1,3) invece, non è una
sua soluzione.

In generale, per equazioni con $n$ incognite si dovrebbe
utilizzare $n$-uple ordinate $(v_1,v_2,\dots,v_n)$: possiamo
allora dare la seguente:
\begin{defi}
  \label{defi:eqlinematrici1}
  Data un'equazione lineare $a_1x_1+a_2x_2+\cdots+a_nx_n=b$ in
  $n$ incognita a coefficienti in un campo $\mathds{K}$, si dice
  \textit{soluzione} dell'equazione una $n$-upla ordinata
  $(v_1,v_2,\dots,v_n)$ di elementi di $\mathds{K}$ tale che
  sostituendo $v_1$ al posto di $x_1,v_2$ al posto di $x_2$ etc.
  fino a $x_n$ l'equazione risulta verificata (ovvero
  l'ugualianza $a_1v_1+a_2v_2+\cdots+a_nv_n=b$ risulta vera).
\end{defi}
Ora, un \textit{sistema di equazioni lineari} è semplicemente un
insieme di equazioni lineari.\\
Per scrivere un generio tale sistema, per risolvere un problema
di notazione simile a quello affrontato quando è stato scritta
la generica equazione lineare, ovvero è necessaria una notazione
efficace per indicare i diversi coefficienti delle incognite
delle incognite nelle diverse equazioni del sistema.\\
A questo scopo, nell'espressione della generica equazione
lineare $a_1x_1+a_2x_2+\cdots+a_nx_n=b$, la seconda $a_{21}x_1+a_{22}x_2+\cdots+a_{2n}x_n=b_2$ e così via.\\
Allora, il generico sistema di equazioni lineari con $n$
incognite e $m$ equazioni (il numero di incognite può anche
essere diverso dal numero di equazioni, perciò li si indica con
due lettere diverse) sarà
\begin{eqnarray}
  \label{eq:eqlinematrici2}
  \begin{pmatrix}
    a_{11} & a_{12} & \cdots & a_{1n}\\
    a_{21} & a_{22} & \cdots & a_{2n}\\
    \vdots & \vdots & & \vdots\\
    a_{m1} &a_{m2} & &a_{mn}
  \end{pmatrix}
  \begin{pmatrix}
    x_1\\
    x_2\\
    \vdots\\
    x_n
  \end{pmatrix}=
  \begin{pmatrix}
    b_1\\
    b_2\\
    \vdots\\
    b_m
  \end{pmatrix}, & \text{oppure,} &
                  \begin{cases}
                    a_{11}x_1 + a_{12}x_2+\cdots+a_{1n}x_n=b_1\\
                    a_{21}x_1+a_{22}x_2+\cdots+a_{2n}x_n=b_2\\
                    \vdots\\
                    a_{m1}x_2+\cdots+a_{mn}x_n=b_m
                  \end{cases}
\end{eqnarray}
In (\ref{eq:eqlinematrici2}) è presente la soluzione dell'equazione,
sia in forma matriciale $Ax=b$ che in forma sistemica -- Visto ciò è
possibile dare la seguente
\begin{defi}
  \label{defi:eqlinematrici2}
  Una soluzione del sistema (\ref{eq:eqlinematrici2}) è una $n$-uple
  $(v_1,v_2\dots,v_n) \in \mathds{K}^n$ che è soluzione comune di tutte le
  equazioni del sistema.

  nel prossimo paragrafo varrà affrontato un algoritmo che consente di
  determinare tutte le soluzione di un sistema. In particolare, si
  scoprirà che possono verificarsi solo le seguenti tre
  possibilità\footnote{Questo è un fatto caratteristico delle equazioni
    lineari: per una generica equazione possono verificarsi anche altri
    casi, ad esempio l'equazione $x^2=9$ ha due soluzione, $x=3$ e
    $x=-3$.}:
  \begin{itemize}
  \item il sistema non ha nessuna soluzione
  \item il sistema ha una sola soluzione
  \item il sistema ha infinite soluzioni
  \end{itemize}
  Prima di entrare nei dettagli, è necessario vedere un esempio di
  ciascuna di queste possibilità, con l'obiettivo di iniziare a capire le
  ragioni per cui essere possono verificarsi.

  Non è difficile essibire un esempio di sistema con infinite soluzioni.
  Ad esempio, considerando il seguente sistema formato da una sola
  equazione in due incognite
  \begin{eqnarray*}
    \begin{cases}
      x_1+x_2=0.
    \end{cases} 
  \end{eqnarray*}
  Una soluzione del sistema è una coppia di numeri reali tali che la
  loro somma dà come risultato zero: questo significa che i numeri
  devono essere uno l'opposto dell'altro, e quindi scelto un qualunque
  $t\in \mathds{R}$, la coppia $(t,-t)$ è una soluzione: le soluzioni
  sono quindi infinite, tante quanti i numeri reali.\\
  Fatto ciò è possibile alla $x_1+x_2=0$ un'altra condizione, ottenendo
  quindi un sistema di due equazioni, ad esempio
  \begin{eqnarray}
    \label{eq:eqlinematrici3}
    \begin{cases}
      x_1+x_2=0 \\
      x_1+x_2=0
    \end{cases} 
  \end{eqnarray}
  Le soluzioni del sistema sono quindi le coppie che soddisfano non solo
  la prima equazione, cioè come detto tette quelle del tipo $(t,-t)$, ma
  anche la seconda, che afferma semplicemente che $x_1=x_2$, cioè i due
  elementi della coppia devono essere non solo opposti ma ache uguali tra
  loro. Ma l'unico numero reale uguale al suo opposto è lo zero, e quindi
  il sistema ha come unica soluzione la coppia (0,0). Questo esempio
  suggerisce che in generale più equazioni ci sono in un sistema,
  maggiori sono i vincoli che imponendo sulle incognite e quindi meno
  $n$-uple ci saranno che soddisfano tutte le condizioni siano sufficienti
  a ottenere una sola soluzione.

  Tuttavia, è facile fare un altro esempio che mostra che questa prima
  impressione non è del tutto esatta: considerando il sistema
  \begin{eqnarray}
    \label{eq:eqlinematrici4}
    \begin{cases}
      x_1+x_2=0 \\
      2x_1+2x_2=0
    \end{cases}
  \end{eqnarray}
  Ora, è immediato vedere che le soluzioni $(t,-t)$ della prima equazionde
  soddisfano tutte anche la seconda, quindi il sistema continua ad avere
  le infinite soluzioni $(t,-t)$. Quest accade perché la seconda equazione
  è in realtà del tutto equivalente alla prima [mettendo in evidenza il
  2, si può riscrivere $2x_1+2x_2=0$ come $2(x_1+x_2)=0$, ovvero,
  dividendo per 2, proprio la prima equazione] e non aggiunge nessun
  nuovo vincolo sulle incognite: si tratta di un'equazione superflua, la
  cui presenza o meno non cambia l'insieme delle soluzioni.\\
  Le equazioni superflue presenti in un sistema possono essere tuttavia
  molto meno evidenti che nel caso appena visto. Ad esempio, consideriando
  il sitema di due equazioni in tre incognite
  \begin{eqnarray}
    \label{eq:eqlinematrici5}
    \begin{cases}
      x_1+x_2+x_3=1\\
      2x_1+x_2+3x_3=2
    \end{cases}
  \end{eqnarray}
  Una qualunque terna $(x_1,x_2,x_3)$ che verifica le due equazioni
  soddisfa necessariamente anche l'ugualianza che si ottiene sommandole
  membro a membro, ovvero
  \begin{eqnarray*}
    (x_1+x_2+x_3) + (2x_1+x_2+3x_3) = 1+2
  \end{eqnarray*}
  cioè, svolgendo i conti,
  \begin{eqnarray*}
    3x_1+2x_2+4x_3=3
  \end{eqnarray*}
  Essendo tale equazione una conseguenza delle prime due, aggiungerla al
  sistema non modifica l'insieme delle soluzioni: in altre parole, il
  sistema
  \begin{eqnarray}
    \label{eq:eqlinematrici6}
    \begin{cases}
      x_1+x_2+x_3=1\\
      2x_1+x_2+3x_3=2\\
      3x_1+2x_2+4x_3=3
    \end{cases}
  \end{eqnarray}
  contiene un'equazione superflua, dipendente dalla altre, certamente meno
  evidente a pria vista che nel caso del sistema
  (\ref{eq:eqlinematrici4}).

  Naturalmente, equazioni superflue possono essere ottenute anche con
  combinazioni più complicate della somma delle prime due equazioni, ad
  esempio sempre in riferimento al sistema (\ref{eq:eqlinematrici5}), una
  terna che soddisfi le due equazioni necessariamente soddisfa anche
  l'ugualianza
  \begin{equation}
    \label{eq:eqlinematrici7}
    5(x_1+x_2+x_3)+(-3)(2x_1+x_2+3x_3)=5\cdot +(-3)\cdot 2
  \end{equation}
  cioè, svolgendo i conti,
  \begin{equation*}
    -x_1+2x_2-4x_3=-1
  \end{equation*}
  ovvero anche nel sistema
  \begin{equation}
    \label{eq:eqlinematrici8}
    \begin{cases}
      x_1+x_2+x_3=1\\
      2x_1+x_2+3x_3=2\\
      -x_1+2x_2-4x_3=-1
    \end{cases}
  \end{equation}
  la terza equazione è superflua, in un modo forse ancora meno evidente.

  Per quello che riguarda i sistemi senza soluzioni, è abbastanza semplice
  esivirne uno. Ad esempio, il sistema di due equazioni in due incognite
  seguente
  \begin{equation*}
    x_1+x_2=0\\
    x_1+x_2=1
  \end{equation*}
  è evidentemente privo di soluzioni, in questo se la somma di due numeri
  è uguale a 0 non può certamentet nello stesso tempo essere uguale a 1.
  In altre parole, le due equazioni del sono tra loro incompatibili,
  ovvero esprimono condizioni contraddittorie.
  Per questo motivo, un sistema che non ha soluzioni si dice
  \textit{incompatibile} (e per contro, si dirà \textit{compatibile} un
  sistema che ha almeno una soluzione).
  Per questo motivo, un sistema che non ha soluzioni si dice
  \textit{incompatibile} (e per contro, si dirà \textit{compatibile} un
  sistema che ha almeno una soluzione).
  Analogamente a quanto fatto sopra per le equazioni superflue, si possono
  costruire esempi di sistemi in cui l'incompatibilità di una equazione
  con le altre non e così evidente come nel semplice sistema precedente.
  Ad esempio, prendiamo sempre come punto di partenza il sistema
  (\ref{eq:eqlinematrici5}). Come visto sopra, una terna che soddisfi le
  due equazioni membro a membro.

  Ma allora, se modifichiamo solo il termine noto di quest'ultima
  uguaglianza, si ottiene una che è incompanibile con le altre due:
  ad esempio, il sistema
  \begin{eqnarray}
    \label{eq:eqlinematrici9}
    \begin{cases}
      x_1+x_2+x_3=1\\
      2x_1+x_2+3x_3=2\\
      3x_1+2x_2+4x_3=5
    \end{cases}
  \end{eqnarray}
  non ha soluzioni, perché per una qualunque terna che soddisfi le prime
  due equaioni si deve avere che $3x_1+2x_2+4x_3$ è uguale a 3, e non a 5.
\end{defi}
\begin{oss}
  \label{oss:eqlinematrici1}
  Un sistema di equazioni in cui i termini noti siano tutti uguali a zero
  (un tale sistema si dice \textit{omogeneo}) ha sempre almeno la
  soluzione $(0,0,\dots,0)$, in quanto ponendo tutte le incognite uguali
  a zeo si ottengono uguaglianza vere. Quindi i sistemi omogenei sono
  sempre compatibili. Vedremo più avanti (Proposizione \ref{}) altre
  importanti caratteristiche dei sistemi omogenei che li distinguono dai
  sistemi non omogenei.
\end{oss}

\section{Matrice di un sistema lineare}
\label{sec:matricediunsistlineare}

Per conoscere un sistema è necessario conoscere, equazione per equazione,
quali sono i coefficienti che moltiplicano ogni singola incognita e i
termini noti. Quindi, se, dato un sistema, si scrive una tabella di
numeri disposti in righe e in colonne in modo che in ogni riga ci siano
i coefficienti delle incognite di una certa equazione (ordinati secondo
l'ordine scelto delle incognite) e il termine noto, tale tabella conterrà
tutte le informazioni che servono sul sistema
\begin{equation}
  \label{eq:matricediunsistlineare1}
  \begin{cases}
    x_1+3x_2=5\\
    2x_1-x_2=4
  \end{cases}
\end{equation}
può essere rappresentato dalla tabella
\begin{equation}
  \label{eq:matricediunsistlineare2}
  \begin{bmatrix}
    1 & 3 & 5\\
    2 & -1 & 4
  \end{bmatrix}
\end{equation}
questa viene chiamata in gergo, \textit{matrice completa del sistema}.
\begin{defi}
  \label{defi:matrice1}
  Una matrice A ad elementi reali è una tabella di numeri reali, detti le
  sue \textit{entrate}
  \begin{equation*}
    A=
    \begin{pmatrix}
      a_{11} & a_{12} & \dots & a_{1n}\\
      a_{21} & a_{22} & \dots & a_{2n}\\
      \vdots & \vdots & \vdots & \vdots\\
      a_{m1} & a_{m2} & \dots & a_{1n}\\
    \end{pmatrix}
  \end{equation*}
  scritti su righe e colonne: se la matrice ha $m$ righe e $n$ colonne,
  si dice che $A$ ha dimensione $m \times n$ oppure si può affermare che
  sia di tipo $m \times n$ o si può anche dire che appartiene a
  $\mathds{R}^{m \times n}$. Se la matrice è ad elementi complessi, si può
  affermare che $A$ appartiene a $\mathds{C}^{m \times n}$.

  Indicando gli elementi della matrice con $a_{ij}$ oppure $(A)_{ij}$
  utilizzando due indici in basso, dove $i$ è l'\textit{indice di riga}
  (dice in quale riga si trova e va da 1 a $m$) e $j$ è \textit{l'indice
    di colonna} (dice in quale colonna si trova e va da 1 a $n$). Si dice
  anche che $a_{ij}$ è l'entrata di posto $ij$.
\end{defi}
\begin{es}
  \label{es:matrice1}
  \textit{Matrice} con 3 righe e 4 colonne
  \begin{equation*}
    \begin{vmatrix}
      6 & -2 & \pi & 0\\
      10 & 3 & 0 & -1\\
      4 & \sqrt{2} & -3 & 1
    \end{vmatrix} \in \mathds{R}^{3 \times 4}
  \end{equation*}
\end{es}
\begin{defi}
  \label{defi:matrice2}
  Per \textbf{trasposta} della matrice $A\in \mathds{R}^{3\times 4}$ si
  intende, la matrice che si indica con $A^T\in \mathds{R}^{3\times 4}$ che
  si ottiene da $A$ scambiando ordinatamente le righe con le colonne
  \begin{equation*}
    (A^T)_{ij}=a_{ji}
  \end{equation*}
\end{defi}
\begin{es}
  \label{es:matrice2}
  Perndendo una matrice $A \in \mathds{R}^{2\times3}$, si otterrà un
  $A^T\in \mathds{R}^{3\times2}$
  \begin{eqnarray*}
    A=
    \begin{bmatrix}
      1 & -1 & 2\\
      2 & 0 & 3
    \end{bmatrix}, & A^T=
                     \begin{bmatrix}
                       1 & 2  \\
                       -1 & 0 \\
                       2 & 3
                     \end{bmatrix}
  \end{eqnarray*}
  (che appare come se fosse stata specchiata e ruotata di $90^o$)
\end{es}
\begin{defi}
  \label{defi:matrice3}
  Per \textbf{sottomatrice} $B\in\mathds{R}^{p\times q}$ di una matrice
  $\mathds{R}^{m \times n}$ si intende, la matrice in cui elementi
  appartengono a $p$ righe e $q$ colonne di $A$.
\end{defi}
\begin{es}
  \label{es:matrice3}
  \begin{equation*}
    \begin{bmatrix}
      6 & \pi & 0\\
      10 & 0 & -1
    \end{bmatrix}
  \end{equation*}
  è una sottomatrice della matrice dell'Esempio \ref{es:matrice1}
  scegliendo prima e seconda riga e prima, terza e quarta colonna.
\end{es}
\begin{oss}
  \label{oss:matrice1}
  se una matrice ha una sola dimensione ($n\times 1$) vengono definiti
  anche vettori.
\end{oss}
\begin{defi}
  \label{defi:matrice4}
  Una matrice di tipo $n\times n$, anche chiamata \textit{matrice
    quadrata} ed il numero $n$ prende il nome di \textit{ordine} della
  matrice. Gli elementi $a_{11},a_{12},\cdots,a_{nn}$ costituiscono la
  \textit{diagonale principale} della matrice.

  Una sottomatrice quadrata di $A\in\mathds{R}^{m\times n}$ viene anche
  definita \textbf{minore estratto da} $A$. Se $A\in\mathds{R}^{m\times n}$
  è quadrata, il \textbf{minore complementare} dell'elemento $a_{ij}$ di
  $A$ è il minore di ordine $n-1$ che si ottiene cancellando da A la
  riga e la colonna a cui appartiene $a_{ij}$ (cancellando riga $i$ e
  colonna $j$).\\
  Nell'ambito delle \textbf{matrici quadrate}, hanno particolare
  importanza i seguenti tipi matrici:
  \begin{itemize}
  \item \textit{simmetrica} se $a_{ij}=a_{ji}$, cioè $A=A^T$;
    \begin{es}
      \label{es:matrice4-1}
      \begin{equation*}
        \begin{bmatrix}
          3 & 7 & -1 & 2\\
          7 & -2 & 0 & 10\\
          -1 & 0 & -12 & 1\\
          2 & 10 & 1 & 6 
        \end{bmatrix}
      \end{equation*}
    \end{es}
  \item \textit{antisimmetrica} se $a_{ij}=-a_{ji}$; si noti che gli
    elementi della diagonale principale devono essere nulli, perché deve
    valere $a_{ii}=-a_{ii}$ ma se un numero reale è uguale al suo opposto
    deve essere per forza 0;
    \begin{es}
      \label{es:matrice4-2}
      \begin{equation*}
        \begin{bmatrix}
          \mathbf{0} & 7 & -2\\
          -7 & \mathbf{0} & 1\\
          2 & -1 & \mathbf{0}
        \end{bmatrix}
      \end{equation*}
    \end{es}
  \item \textit{triangolare superiore} se $a_{in}=0$ per $i>j$;
    \begin{es}
      \label{es:matrice4-3}
      \begin{eqnarray*}
        \begin{bmatrix}
          3 & 7 & -2\\
          \mathbf{\color{blue}0} & 11 & 1\\
          \mathbf{\color{blue}0} & \mathbf{\color{blue}0} & -5
        \end{bmatrix} & a_{21} = a_{31} = a_{32} = 0
      \end{eqnarray*}
    \end{es}
  \item \textit{triangolare inferiore} se $a_{ij}=0$ per $i<j$;
    \begin{es}
      \label{es:matrice4-4}
      \begin{eqnarray*}
        \begin{bmatrix}
          3 & \mathbf{\color{blue}0} & \mathbf{\color{blue}0}\\
          -7 & 5 & \mathbf{\color{blue}0}\\
          12 & -1 & 4
        \end{bmatrix} & a_{12}=a_{13}=a_{23}=0
      \end{eqnarray*}
    \end{es}
  \item \textit{diagonale} se $a_{ij}=0$ per $i\neq j$.
    \begin{es}
      \label{es:matrice4-5}
      \begin{equation*}
        \begin{bmatrix}
          4 & 0 & 0\\
          0 & -2 & 0\\
          0 & 0 & 9
        \end{bmatrix}
      \end{equation*}
      In particolare, se gli elementi diagonali sono uguali a 1, tale
      matrice si chiama \textbf{matrice identità} e si indica col simbolo
      $I$ (o $I_n$ se si vuole evidenziare il suo ordine)
      \begin{equation*}
        I_4=
        \begin{bmatrix}
          1 & 0 & 0 & 0\\
          0 & 1 & 0 & 0\\
          0 & 0 & 1 & 0\\
          0 & 0 & 0 & 1
        \end{bmatrix}
      \end{equation*}
      \begin{lstlisting}[caption=generare una matrice identità in GNU/Octave]
        > eye(4)
        ans =
        
        Diagonal Matrix

        1   0   0   0
        0   1   0   0
        0   0   1   0
        0   0   0   1
      \end{lstlisting}
    \end{es}
  \end{itemize}
\end{defi}
\begin{defi}
  \label{defi:matrice5}
  La \textbf{traccia} di una matrice quadrata $A$ è il numero dato dalla
  somma degli elementi sulla diagonale
  \begin{equation*}
    \mathrm{tr}(A)=a_{11}+a_{22}+\cdots+a_{nn}.
  \end{equation*}
\end{defi}
\begin{es}
  La traccia della matrice dell'Esempio \ref{es:matrice4-1} è
  $\mathrm{tr}(A)=3-2-12-6=-5$.
\end{es}
Considerando una matrice rettangolare $A\in\mathds{R}^{m\times n}$.
\begin{defi}
  \label{defi:matrice6}
  Una matrice viene detta \textbf{a gradini} se dalla prima all'ultima
  riga, il primo elemento non nullo di ogni riga compare con un indice di
  colonna sempre più grande. Il primo elemento non nullo di ogni riga è
  chiamato \textit{pivot}.
  \begin{es}
    \label{es:matrice6-1}
    \begin{equation*}
      \begin{bmatrix}
        7 & 1 & 1 & 3 \\
        0 & 4 & 3 & 5 \\
        0 & 0 & 0 & 6
      \end{bmatrix}
    \end{equation*}
    è una matrice a gradini. I suoi \textit{pivot} sono 7 nella prima
    seconda, 4 nella seconda, 6 nella terza, nell'ordine, sulla prima,
    seconda e quarta colonna (indice di colonna viene incrementato più si
    scende nella matrice).
  \end{es}
  \begin{es}
    \label{es:matrice6-2}
    \begin{equation*}
      \begin{bmatrix}
        7 & 1 & 1 & 3 \\
        0 & 4 & 3 & 5 \\
        0 & 2 & 0 & 6
      \end{bmatrix}
    \end{equation*}
    non è a gradini. Il primo elemento non nullo della terza riga sta
    nella stessa colonna del primo elemento nullo della seconda riga.
  \end{es}
  \begin{es}
    \label{es:matrice6-3}
    \begin{equation*}
      \begin{bmatrix}
        7 & 1 & 1 & 3 \\
        0 & 0 & 3 & 5 \\
        0 & 2 & 0 & 6
      \end{bmatrix}
    \end{equation*}
    non è a gradini. Il primo elemento non nullo della riga sta in una
    colonna di indice più piccolo del primo elemento non nullo della
    seconda riga.
  \end{es}
  \begin{es}
    \label{es:matrice6-4}
    Altri esempi di matrici a gradini sono le diagonali e le matrici
    triangolari superiori con gli elementi sulla diagonale principale
    diversi da zero.
  \end{es}
\end{defi}

\section{Operazioni tra matrici}
\label{sec:opmatrici}

\subsection{Somma di matrici}
\label{sec:somdimatrici}

Siano $A$ e $B$, due matrici dello stesso tipo $m\times n$. Gli elementi
della matrice $A+B$, anche detta \textbf{somma} di $A$ e $B$, si ottengono
sommando elementi aventi lo stesso posto in $A$ e $B$, cioè
\begin{eqnarray*}
  (A+B)_{ij}=a_{ij}+b_{ij} & i=1,\cdots,m, & j=1,\cdots,n.
\end{eqnarray*}
\begin{es}
  \label{es:sommatrice1}
  \begin{eqnarray*}
    A=
    \begin{bmatrix}
      \frac{7}{10} & -1 & \frac{1}{4}\\
      0 & 3 & \frac{1}{2}
    \end{bmatrix}, & B=
                    \begin{bmatrix}
                      0 & \frac{1}{2} & \frac{3}{4}\\
                      -2 & 1 & \frac{1}{2}
                    \end{bmatrix}, & A+B=
                                    \begin{bmatrix}
                                      \frac{7}{10} & -\frac{1}{2} & 1\\
                                      -2 & 4 & 1
                                    \end{bmatrix}
  \end{eqnarray*}
\end{es}

\paragraph{Proprietà:}

siano $A,B,C\in \mathds{R}^{m\times n}$, valgono le seguenti
\begin{description}
\item[Proprietà commutativa] $A+B=B+A$
\item[Proprietà associativa] $(A+B)+C=A+(B+C)$
\item[La matrice nulla $O$] (formata da tutti zeri) è tale che
  $A+O=O+A=A$ 
\item[La matrice di $-A$] (opposta di $A$) i cui elementi sono gli opposti
  dei relativi elementi di $A$ è tale che $A+(-A)=O$
\end{description}
La \textbf{differenza} tra matrice dello stesso tipo è definita da
\begin{equation*}
  A-B=A+(-B)
\end{equation*}

\subsection{Prodotto di uno scalare per una matrice}
\label{sec:prodmatrice}

Sia $A\in \mathds{R}^{m\times n}$ e $\lambda \in \mathds{R}$. Il
\textbf{prodotto} di $\lambda$ per $A$ è la matrice $\lambda A$ i quali
elementi sono ottenuti moltiplicando per $\lambda$ i corrispondenti
elementi di $A$, cioè
\begin{eqnarray*}
  (\lambda A)_{ij}=\lambda a_{ij} & i = 1,\dots,m, & j=1,\dots,n.
\end{eqnarray*}
\begin{es}
  \label{es:prodmatrice1}
  \begin{equation*}
    3
    \begin{bmatrix}
      -2 & 1 & 0\\
      4 & -1 & 2
    \end{bmatrix} =
    \begin{bmatrix}
      -6 & 3 & 0\\
      12 & -3 & 6
    \end{bmatrix}
  \end{equation*}
  
\end{es}

\paragraph{Proprietà}

siano $A,B\in \mathds{R}^{m\times n}$ e $\lambda, \mu \in \mathds{R}$, valgono le
seguenti
\begin{enumerate}
\item $\lambda (A+B)=\lambda A+\lambda B$
\item $(\lambda + \mu)A=\lambda A+\mu A$
\item $\lambda (\mu A)=(\lambda\mu) A$
\item $1A=A$
\end{enumerate}
\begin{oss}
  \label{oss:prodmatrice1}
  L'insieme delle matrici di tipo $m\times n$ dotato delle operazioni di
  somma di matrici e prodotto di uno scalare per una matrice è uno
  spazio vettoriale.
\end{oss}

\subsection{Prodotto di matrici (righe per colonne)}
\label{sec:prodmtxrigcol}

Siano $A\in \mathds{R}^{m\times n}$ e $B\in \mathds{R}^{n\times p}$ (il numero di
colonne in $A$ coincidono con il numero di righe in $B$) il \textbf{prodotto} delle
matrici $A$ e $B$ è la matrici
\begin{equation*}
  AB\in \mathds{R}^{m\times p}
\end{equation*}
il cui elemento generico è dato da
\begin{eqnarray}
  \label{eq:prodmtxrigcol1}
  (AB)_{ij}=\sum_{k=1}^na_{ik}b_{kj} & i=1,\cdots,m; & j = 1,\cdots,p
\end{eqnarray}
cioè la matrice prodotta ha numero di righe pari a quello della matrice di sinistra
e numero di colonne pari a quello della matrice di destra, e il suo generico elemento
è la somma dei prodotti degli elementi della riga di posto $i$ nella matrice $A$ per
i corrispondenti elementi della colonna di posto $j$ nella matrice B.
Ecco come diventa la formula (\ref{eq:prodmtxrigcol1}) se $A\in \mathds{R}^{2\times3}$
e $B\in \mathds{3\times 2}$, andando a scrivre gli elementi della matrice prodotto:
\begin{eqnarray}
  \label{eq:prodmtxrigcol2}
  \underbrace{\begin{bmatrix}
    a_{11} & a_{12} & a_{13}\\
    a_{21} & a_{22} & a_{23}
  \end{bmatrix}}_{A}
  \underbrace{\begin{bmatrix}
    b_{11} & b_{12} \\
    b_{21} & b_{22} \\
    b_{31} & b_{32}
  \end{bmatrix}}_{B}=
  \underbrace{\begin{bmatrix}
    c_{11} & c_{12}\\
    c_{21} & c_{22} 
  \end{bmatrix}}_{AB} &
                  \begin{matrix}
                    c_{11}=a_{11}b_{11} + a_{12}b_{21} + a_{13} b_{31}\\
                    c_{12}=a_{11}b_{12} + a_{12}b_{22} + a_{13} b_{32}\\
                    c_{21}=a_{23}b_{11} + a_{22}b_{21} + a_{23} b_{31}\\
                    c_{22}=a_{21}b_{12} + a_{22}b_{22} + a_{23} b_{32}
                  \end{matrix}
\end{eqnarray}
\begin{es}
  \label{es:prodmtxrigcol1}
  Prodotto tra una matrice $A$ di tupo $2\times 3$ una $B$ di tipo $3\times 2$
  \begin{eqnarray*}
    AB=
    \begin{bmatrix}
      4 & 5 & 3 \\
      2 & 3 & 1
    \end{bmatrix}\cdot
    \begin{bmatrix}
      2 & 3 \\
      4 & 1 \\
      9 & 2
    \end{bmatrix} =
    \begin{bmatrix}
      4\cdot 2 + 5 \cdot 3 + 3\cdot 9 & 4 \cdot 3 + 5 \cdot 1 + 3 \cdot 2\\
      2\cdot 2 + 5 \cdot 4 + 3\cdot 9 & 4 \cdot 2 + 3 \cdot 3 + 1 \cdot 3
    \end{bmatrix}
    =
    \begin{bmatrix}
      55 & 23\\
      25 & 11
    \end{bmatrix}
  \end{eqnarray*}
  La matrice prodotto è di tipo $2\times 2$. Riportando questa operazione su
  GNU/Octave:
  \begin{lstlisting}[caption=moltiplicazione riga per colonna]
    A = [ 4 5 3; 2 3 1 ];
    B = [ 2 3; 4 1; 9 2 ];
    C=A*B;
    disp (C);
  \end{lstlisting}
\end{es}
\begin{oss}
  \label{oss:prodmtxrigcol1}
  Se ha senseo calcolare $AB$, in generale non può avere senso calcolare $BA$.
  Nell'Esempio \ref{es:prodmtxrigcol1} ha senso calcolare $BA$. 
\end{oss}
\begin{oss}
  \label{oss:prodmtxrigcol2}
  Anche se entrambi i prodotti possono si possono eseguire, come avviene ad
  esempio $A$ e $B$ sono quadrate dello stesso ordine, in genere
  \begin{equation*}
    AB\neq BA
  \end{equation*}
  da questo si deduce che il prodotto tra matrici non gode della proprietà
  commutativa.
\end{oss}
\begin{es}
  \label{es:prodmtxrigcol2}
  \begin{eqnarray*}
    \begin{bmatrix}
      2 & -1\\
      3 & \frac{5}{4}
    \end{bmatrix}
    \begin{bmatrix}
      1 & 0 \\
      2 & -4
    \end{bmatrix}=
    \begin{bmatrix}
      0 & 4\\
      \frac{11}{2} & -5
    \end{bmatrix}\\
    \begin{bmatrix}
      1 & 0 \\
      2 & -4
    \end{bmatrix}
    \begin{bmatrix}
      2 & -1 \\
      3 & \frac{5}{4}
    \end{bmatrix}=
    \begin{bmatrix}
      2 & -1 \\
      -8 & -7
    \end{bmatrix}
  \end{eqnarray*}
  Si può dimostrare se $AB=BA$, qualunque sia la matrice $A$ di ordine $n$, allora
  $B=\lambda I_n$.
  
  \paragraph{Proprietà} purché le operazioni indicate abbiano senso (\textit{in base
    alle dimostrazioni delle matrici}), valgono le sequenti
  \begin{enumerate}
  \item $A(B+C)=AB+AC$, $(A+B)C=AC+BC$
  \item $A(BC)=(AB)C$
  \item $A(\lambda B)=\lambda (AB)$, $(\lambda A)B=\lambda(AB)$
  \end{enumerate}
\end{es}
\begin{oss}
  \label{oss:prodmtxrigcol2}
  Nel prodotto tra matrici non vale la \textit{legge di annullamento del
    prodotto}\footnote{Se due numeri $a$ e $b$ danno prodotto zero $ab=0$, allora
    almeno uno dei fattori è zero.}. Quindi si può ottenere la matrice nulla $AB=O$
  anche se $A$ e $B$ non sono matrici nulle. per esempio
  \begin{equation*}
    \begin{bmatrix}
      0 & 1 \\
      0 & 0
    \end{bmatrix}\cdot
    \begin{bmatrix}
      1 & 0 \\
      0 & 0
    \end{bmatrix} =
    \begin{bmatrix}
      0 & 0 \\
      0 & 0
    \end{bmatrix}
  \end{equation*}
\end{oss}
\begin{oss}
  \label{oss:prodmtxrigcol3}
  Se la matrice $A$ è quadrata, ha senso $A^2=AA, A^3=AAA, A^P=AA\cdot{}A$, detta
  \textit{potenza p-esima} della matrice A. Inoltre se $I_n$ è la matrice identità di
  ordine $n$, vale $AI_n=I_nA=A$.
\end{oss}
\begin{prop}
  \label{prop:prodmtxrigcol1}
  Siano $A\in\mathds{R}^{m\times n}$ e $B\in \mathds{R}^{m\times p}$, Allora vale
  \begin{equation*}
    (AB)^T=B^TA^T
  \end{equation*}
  \begin{proof}
    \begin{eqnarray*}
      ((AB)^T)_{ij}=(AB)_{ji}=\sum_{k=1}^na_{jk}b_{kj}\\
      (B^TA^T)=\sum_{k=1}^n(B^T)_{jk} (A^T)_{kj}=\sum_{k=1}^nb_{kj}a_{jk}
    \end{eqnarray*}
    e le due espressioni sono uguali perché prodotto di due scalari è communtativo.
  \end{proof}
\end{prop}

\section{Il determinante}
\label{sec:determinante}

Data una matrice quadrata di ordine $n$ a entrate in un campo $\mathds{K}$ (che può
essere $\mathds{R}$ o $\mathds{C}$)
\begin{equation*}
  A=
  \begin{bmatrix}
    a_{11} & a_{12} & \dots & a_{1n}\\
    a_{21} & a_{22} & \dots & a_{2n}\\
    \vdots & \vdots & \vdots& \vdots\\
    a_{n1} & a_{n2} & \dots & a_{nn}
  \end{bmatrix}
\end{equation*}
ad essa si associa un numero appartenente a $\mathds{K}$, detto \textbf{determinante}
della metrice, che è funzione delle sue entrate
\begin{equation*}
  \det(A)=
  \begin{bmatrix}
    a_{11} & a_{12} & \dots & a_{1n}\\
    a_{21} & a_{22} & \dots & a_{2n}\\
    \vdots & \vdots & \vdots& \vdots\\
    a_{n1} & a_{n2} & \dots & a_{nn}
  \end{bmatrix}
\end{equation*}
Se la matrice ha ordine $n\leq 3$, il suo determinente è così definito:
\begin{itemize}
\item per $n=1$, $\det(A)$ coincide con l'unico elemento della matrice;
\item per $n=2$, si pone
  \begin{equation*}
    \det(A)=
    \begin{pmatrix}
      a_{11} &a_{12}\\
      a_{21} & a_{22}
    \end{pmatrix}= a_{11}a_{22}-a_{12}a_{21}
  \end{equation*}
\item per $n=3$, si pone
  \begin{eqnarray*}
    \det(A)=
    \begin{pmatrix}
      a_{11} & a_{12} & a_{13}\\
      a_{21} & a_{22} & a_{23}\\
      a_{31} & a_{32} & a_{33}
    \end{pmatrix}= a_{11}
    \begin{bmatrix}
      a_{22} & a_{23}\\
      a_{32} & a_{33}
    \end{bmatrix} - a_{12}
    \begin{bmatrix}
      a_{21} & a_{23}\\
      a_{31} & a_{33}
    \end{bmatrix}+
    a_{13}
    \begin{bmatrix}
      a_{21} & a_{22}\\
      a_{31} & a_{32}
    \end{bmatrix}\\
    = a_{11}(a_{22}a_{33}-a_{23}a_{32})-a_{12}(a_{21}a_{33}-a_{23}a_{31})+a_{13}
    (a_{21}a_{32}-a_{22}a_{31})
  \end{eqnarray*}
\end{itemize}
Per estendere la definizione di determinante al caso $n$ generale, è necessaria una
premessa sulle permutazioni.

\section{Permutazioni}
\label{sec:perm}

Dato l'insieme $\{1,2,\cdots, n\}$ dei numeri naturali compresi tra 1 e n, una
funzione da questo insieme in se stesso associa ad ogni elemento di $\{1,2,\dots,n\}$
un immagine, scelta sempre all'interno di $\{1,2,\cdots,n\}$. Se le immagini sono
tutte diverse zenza ripetizioni, queste saranno ancora tutti gli elementi
$1,2,\dots,n$ semplicemente disposti in un altro ordine, ovvero permutati. Si tratta
allor di \textbf{permutazione di $n$ elementi}.
\begin{es}
  \label{es:perm1}
  Le seguenti rappresentano permutazioni di 4 elementi:
  \begin{eqnarray*}
    1 \to 1 && 1 \to 3\\
    2 \to 3 && 2 \to 4\\
    3 \to 2 && 3 \to 2\\
    4 \to 4 && 4 \to 1
  \end{eqnarray*}
  L'insieme delle permutazioni di $n$ eleemnti si denota $S_n$. Per ogni $n$, tale
  insieme contiene esattamente $n!:= n(n-1)(n-2)\cdots 2 \cdot 1$ (cioè $n$
  fattoriale) permutazioni: ad esempio per $n=2$ si ottiene $2\cdot 1=2$ permutazioni
  possibili, ovvero
  \begin{equation*}
    \begin{matrix}
      1\to 1 && 1\to 2\\
      2\to 2 && 2\to 1
    \end{matrix}
  \end{equation*}
  Tra le permutazioni, vi è sempre anche quella che associa a ogni elemento se stesso,
  detta \textit{permutazione identica}.
\end{es}
Per $n=3$ si ottiene invece $3! = 3\cdot 2\cdot 1 = 6$ permutazioni possibili,
ovvero
\begin{equation*}
  \begin{matrix}
    p_1 & p_2 & p_3 & p_4 & p_5 & p_6\\
    1 \to 1 & 1 \to 2 & 1 \to 1 & 1 \to 3 & 1 \to 2 & 1 \to 3 \\
    2 \to 2 & 2 \to 1 & 2 \to 3 & 2 \to 2 & 2 \to 3 & 2 \to 1 \\
    3 \to 3 & 3 \to 3 & 3 \to 2 & 3 \to 1 & 3 \to 1 & 3 \to 2
  \end{matrix}
\end{equation*}
Si noti che $p_2$, $p_3$ e $p_4$ scambiano tra loro due elementi fisso il terzo
($p_2$ scambia tra loro 1 e 2, $p_3$ scambia loro 2 e 3, $p_4$ scambia tra loro 1 e
3): in genere, una permutazione di questo tipo, che scambia tra loro due elementi
lasciando fissi tutti gli altri elementi presentata nell'esempio \ref{es:perm},
(scambia tra loro 2 e 3 lasciando fissi 1 e 4), mentre la seconda non lo è. Benché
non tutte le permutazioni sieno trasposizioni, qualunque realizzata eseguendo può
esssere ottenuta come composizione di trasposizioni, ovvero può essere permutazione
può essere ottenuta come composizioni di trasposizioni, ovvero può essere realizzata
eseguendo una sequenza di trasposizioni. Ad esempio, la permutazione $p_5$ di sopra,
che non è una trasposizione, può tuttavia essere ottenuta scambiando prima 1 e 2, e
poi 1 e 3, cioè componentdo 2 trasposizioni:
\begin{equation*}
  \begin{matrix}
    1 \to 2 \to 2\\
    2 \to 1 \to 3\\
    3 \to 3 \to 1
  \end{matrix}
\end{equation*}
In genere, se il numero di trasposizioni che servono per ottenere una permutazione
$p$ è pari, si dice che $p$ è una \textbf{permutazione pari}, se invece, il numero
di trasposizioni che servono per ottenere $p$ è dispari, si dice che $p$ sia una
\textbf{permutazione dispari}. Ad esempio, $p_5$ è una permutazione pari, in quanto
è stato ottenuto componendo 2 trasposizioni.
\begin{oss}
  \label{oss:perm1}
  Se una permutazione è già essa una trasposizione, allora essa è dispari (1 è un
  numero dispari).
\end{oss}
\begin{oss}
  \label{oss:perm2}
  Possono esserci più modi diversi di decomporre una permutazione come composizione
  di trasposizioni, ad esempio, la permutazione identica può essere vista o come
  risultato di $0$, oppure come risultato di 2 trasposizioni
  \begin{equation*}
    \begin{matrix}
      1 \to 2 \to 1\\
      2 \to 1 \to 2\\
      3 \to 3 \to 3
    \end{matrix}
  \end{equation*}
  Tuttavia, si può dimostrare che il numero di trasposizioni che servono per
  ottenere una permutazione data è o sempre pari o sempre dispari (nell'esempio, 0
  o 2, comunque pari).
\end{oss}
Si può allora definire il \textbf{segno} $s(p)$ di una permutazione $p$ come
\begin{itemize}
\item $s(p)=+1$ se $p$ è una permutazione pari;
\item $s(p)=-1$ se $p$ è una permutazione dispari.
\end{itemize}

\subsection{Determinante}
\label{sec:determinante}

\begin{defi}
  \label{defi:determinante1}
  Sia $A$ una matrice quadrata di ordine $n$ con entrate $a_{ij}$. Il determinante è
  definito da
  \begin{equation}
    \label{eq:determinante1}
    \det (A)=\sum_{p\in S_n}s(p)\cdot a_{1p(1)}a_{2p(2)}\cdots a_{np(n)}
  \end{equation}
  Il determinante è dato da una sommatoria che ha un addendo per ogni permutazione
  $p\in S_n$: ognuno di questi addendi è un prodotto di entrate di $A$ del tipo
  $a_{1p(1)}a_{2p(2)}\cdots a_{np(n)}$, con davanti un $+$ o $-$ a seconda che la
  permutazione $p$ sia pari o dispari. Si noti che l'espressione
  $a_{1p(1)}a_{2p(2)}\cdots a_{np(n)}$ è il prodotto di $n$ entrate scelte nella
  matrice, una per scambia gli undici $1,2,\dots,n$ senza ripetizioni, si sceglie
  un'entrata da ogni riga che le entrate scelte stiano anche su colonne diverse.
\end{defi}
Per chiarire la definizione, si prende i casi $n = 2$ e $n=3$.

Sia $n=2$ e $A=
\begin{bmatrix}
  a_{11} & a_{12}\\
  a_{21} & a_{22}
\end{bmatrix}
$. Dell'insieme $\{1,2\}$ ci sono 2 permutazioni (l'identità e la trasposizione 1
con 2), quindi nella sommatoria (\ref{eq:determinante1}) ci saranno solo due
addendi, del tipo $s(p)$ e $a_{1p(1)}a_{2p(2)}$:
\begin{itemize}
\item se $p$ è l'identità (permutazione pari) si ha $s(p)=+1$, l'addendo
  corrispondente sarà $+a_{12} a_{21}$.
\item se $p$ è la trasposizione che scambia 1 con 2 (permutazione dispari), si ha
  $s(p)=-1$ e l'addendo corrispondente sarà $-a_{12} a_{21}$.
\end{itemize}
Quindi il determinante risulta essere $\det(A)=a_{11}a_{22} -a_{12} a_{21}$.

Sia $n=3$ e $A=
\begin{bmatrix}
  a_{11} & a_{12} & a_{13}\\
  a_{21} & a_{22} & a_{23}\\
  a_{31} & a_{32} & a_{33}
\end{bmatrix}
$. Le permutazioni dell'insieme $\{1,2,3\}$ sono $3!=6$, quindi la sommatiria
(\ref{eq:determinante1}) avrà il addendi: per ognuna di queste permutazioni $p$
l'addendo corrispondente sarà del tipo $s(p)\cdot a_{1p(1)}a_{2p(2)}\cdots a_{np(n)}$.
Più precisamente si avranno gli addendi:
\begin{itemize}
\item $+a_{11}a_{22}a_{33}$ corrispondente alla permutazione $p(1)=1,p(2)=2, p(3)=3$
  (permutazione identica, che è una permutazione pari)
\item $-a_{11}a_{23}a_{32}$ corrispondente alla permutazione $p(1)=1,p(2)=3, p(3)=2$
  (una trasposizione, non per altro è una permutazione dispari)
\item $+a_{12}a_{21}a_{32}$ corrispondente alla permutazione $p(1)=2,p(2)=3, p(3)=1$
  (composizione di due trasposizioni, quindi permutazione pari)
\item $-a_{13}a_{21}a_{33}$ corrispondente alla permutazione $p(1)=2,p(2)=1, p(3)=3$
  (composizionde di due trasposizioni, non per altro è una permutazione dispari)
\item $+a_{13}a_{21}a_{32}$ corrispondente ala permutazione
  $p(1)=3,p(2)=1,p(3)=2$ (è una composizione di due trasposizioni, quindi
  una permutazione pari)
\item $-a_{13}a_{22}a_{31}$ corrisponde alla permutazione $p(1)=3, p(2)=2, p(3)=1$ (una trasposizione, quindi una permutazione dispari).
\end{itemize}
Quindi il determinante risulta essere
\begin{equation*}
  \det(A)=a_{11}a_{22}a_{33}-a_{11}a_{23}a_{32}+a_{12}a_{21}a_{32}-a_{13}a_{21}a_{33}+a_{13}a_{21}a_{32}-a_{13}a_{22}a_{31}
\end{equation*}
È necessario introdurre un metodo per calcolare il determiannte,
alternativo alla definizione, il cui utilizzo diretto richiederebbe di
scrivere una sommatoria che per una matrice di ordine $n$ a $n!$ addendi,
tanti quanti le permutazioni di $n$ elementi (si pensi che già per $n=4$
abbiamo $4!=24$ addendi). Allo scopo di calcolare il determinante,
verrà utilizzata la \textit{formula di Laplace}.

\subsection{Formula di Laplace}
\label{sec:formlaplace}
\begin{oss}
  \label{oss:formlaplace}
  Per calcolare il prodotto vettoriale tra due vettori $x$ e $y$ non è
  necessario studiare a emoria la formula, perché si può ricavare
  calcolando il determinante di una matrice $3\times 3$. Tale matrice si
  costruisce in questo modo:
  \begin{itemize}
  \item nella prima riga bisogna disporre le lettere $i,j,k$, che indicano
    i versori della base canonica in $\mathds{R}^3$;
  \item nella seconda riga le coordinate del vettore $x$;
  \item nella terza riga le coordinate del vettore $y$.
  \end{itemize}
  Calcolando il determinante (sviluppando Laplace secndo la prima riga),
  si ottiene
  \begin{equation*}
    \begin{bmatrix}
      \mathbf{i} & \mathbf{j} &\mathbf{k}\\
      x_1 & x_2 & x_3\\
      y_1 & y_2 & y_3
    \end{bmatrix}=(x_2y_3-x_3y_2)\mathbf{i}-(x_1y_3-x_3y_1)\mathbf{j}
    +(x_1y_2-x_2y_1)\mathbf{k}
  \end{equation*}
  che sono proprio le coordinate del vettore $x\wedge y=
  \begin{bmatrix}
    x_2y_3-x_3y_2\\
    x_1y_3-x_3y_1\\
    x_1y_2-x_2y_1
  \end{bmatrix}
  $
\end{oss}

\subsection{Proprietà del determinante}
\label{sec:prodeldet}
\begin{pro}
  \label{pro:prodeldet1}
  Il determiannte di una matrice è uguale a quello della sua trasposta
  \begin{equation*}
    \det(A)=\det(A^T)
  \end{equation*}
\end{pro}
\begin{es}
  \label{es:prodeldet1}
  \begin{eqnarray*}
    \begin{pmatrix}
      -2 & 3 & 1\\
      0 & 1 & -3\\
      1 & -3 & 5
    \end{pmatrix}=-2
    \begin{pmatrix}
      1 &-3\\
      2 & 5
    \end{pmatrix}= -2(5+6)=-22\\
    \begin{pmatrix}
      -2 & 0 & 0\\
      3 & 1 & 2 \\
      1 & -3 & 5
    \end{pmatrix}= -2
    \begin{pmatrix}
      1 & 2\\
      -3 & 5
    \end{pmatrix}=-2(5+6)=-22
  \end{eqnarray*}
\end{es}
\begin{pro}
  \label{pro:prodeldet2}
  Il determinante di una matrice triangolare (inferiore o superiore) è
  uguale al prodotto degli elementi della diagonale principale
  \begin{equation*}
    \begin{pmatrix}
      a_{11} & a_{12} & \cdots & a_{1n}\\
      0 & a_{22} & \cdots & a_{2n}\\
      \vdots & \vdots & \vdots & \vdots\\
      0 & 0 & \cdots & a_{nn}
    \end{pmatrix}=a_{11}a_{22}\dots a_{nn}
  \end{equation*}
  Il perticolare, anche il determiannte di una matrice diagonale è uguale
  al prodotto degli elementi della diagonale principale.
\end{pro}
\begin{es}
  \label{es:prodeldet2}
  \begin{equation*}
    \begin{bmatrix}
      2 & 16 & -50\\
      0 & 1 & 2022\\
      0 & 0 & -5
    \end{bmatrix}=-10
  \end{equation*}
\end{es}
\begin{pro}
  \label{pro:prodeldet3}
  Se gli elementi di una riga o di una collona sono moltiplicati per uno
  stesso numero $c\in\mathds{R}$, il determinante dato da $c\det (A)$
  \begin{equation*}
    \begin{bmatrix}
      ca_{11}& ca_{12} & ca_{13}\\
      a_{21} & a_{22} & a_{23}\\
      a_{31} & a_{32} & a_{33}
    \end{bmatrix}=c
    \begin{bmatrix}
      a_{11} & a_{12} & a_{13}\\
      a_{21} & a_{22} & a_{23}\\
      a_{31} & a_{32} & a_{33}
    \end{bmatrix}
  \end{equation*}
\end{pro}
\begin{es}
  \label{es:prodeldet3}
  \begin{equation*}
    \det(A)=
    \begin{bmatrix}
      1 & 0 & 0\\
      2 & 3 & 5\\
      6 & 1 & 2
    \end{bmatrix}=1
    \begin{bmatrix}
      3 & 5\\
      1 & 2
    \end{bmatrix}=6-5=1
  \end{equation*}
  Se viene moltiplicata la prima colonna per 2
  \begin{equation*}
    \begin{bmatrix}
      2 & 0 & 0\\
      4 & 3 & 5\\
      12 & 1 & 2
    \end{bmatrix}=2
    \begin{bmatrix}
      3 & 5\\
      1 & 2
    \end{bmatrix}=2(6-5)=2 =2\det(A)
  \end{equation*}
\end{es}
\begin{pro}
  \label{pro:prodeldet4}
  Se gli elementi di una riga o di una colonna sono somma di due
  addendi, il determinante è la somma dei determinanti delle due matrici
  che si ottengono da $A$ sostiduendo agli elementi della colonna in
  questione i primi o i secondi addendi (e lasciando fissi gli altri)
  \begin{equation*}
    \begin{pmatrix}
      a_{11}& a_{12} + b_{12} & a_{13}\\
      a_{21}& a_{22} + b_{22} & a_{23}\\
      a_{31}& a_{32} + b_{32} & a_{33}
    \end{pmatrix}=
    \begin{pmatrix}
      a_{11} & a_{12} & a_{13}\\
      a_{21} & a_{22} & a_{23}\\
      a_{31} & a_{32} & a_{33}
    \end{pmatrix}
    +
    \begin{pmatrix}
      a_{11} & a_{12} & a_{13}\\
      a_{21} & a_{22} & a_{23}\\
      a_{31} & a_{32} & a_{33}
    \end{pmatrix}
  \end{equation*}
\end{pro}
\begin{es}
  \begin{equation*}
    \begin{pmatrix}
      1 & 5\\
      -2 & 7
    \end{pmatrix}=
    \begin{pmatrix}
      1 & 2\\
      -2 & 6
    \end{pmatrix}+
    \begin{pmatrix}
      1 & 3 \\
      -2 & 1
    \end{pmatrix}
  \end{equation*}
  Gli elementi della seconda colonna sono somma di due addendi. Il
  determinante a sinitra è 17. Mentre a destra $10+7$.
\end{es}
\begin{pro}
  \label{pro:prodeldet5}
  Scambiando fra loro due righe o due colonne di una matrice, il
  corrispondente cambia di segno.
\end{pro}
\begin{es}
  \label{es:prodeldet5}
  \begin{equation*}
    \begin{pmatrix}
      1 & 0 & 0\\
      2 & 3 & 5\\
      6 & 1 & 2
    \end{pmatrix}=1
    \begin{pmatrix}
      3 & 5\\
      1 & 2
    \end{pmatrix}= 6-5=1
  \end{equation*}
  Scambio seconda e terza riga
  \begin{equation*}
    \begin{pmatrix}
      1 & 0 & 0 \\
      6 & 1 & 2 \\
      2 & 3 & 5
    \end{pmatrix}=1
    \begin{pmatrix}
      1 & 2\\
      3 & 5
    \end{pmatrix}=5-6=-1
  \end{equation*}
\end{es}
\begin{pro}
  \ref{pro:prodeldet6}
  Il determinante di una matrice con due righe o due colonne uguali
  è nullo. Infatti lo scambio di tali righe (o colonne) non altera il
  determinante, ma per la Proprietà \ref{pro:prodeldet5} deve essere
  $\det (A)=-\det(A)$, quindi $\det(A)=0$.
\end{pro}
\begin{pro}
  \ref{pro:prodeldet7}
  Se agli elementi di una riga si sommano gli elementi di un'altro riga
  moltiplicata per un numero, il determinante non cambia. In particolare
  se $n=3$
  \begin{equation*}
    A=
    \begin{bmatrix}
      a_{11} & a_{12} & a_{13}\\
      a_{21} & a_{22} & a_{23}\\
      a_{31} & a_{32} & a_{33}
    \end{bmatrix}
  \end{equation*}
  Se per esempio alla seconda riga sommiamo la terza riga moltiplicata per
  un numero $c$, si ottiene la matrice
  \begin{equation*}
    A^\prime =
    \begin{bmatrix}
      a_{11} & a_{12} & a_{13}\\
      a_{21}+ca_{31} & a_{22}+ca_{32} & a_{23}+ca_{33}\\
      a_{31} & a_{32} & a_{33}
    \end{bmatrix}
  \end{equation*}
  Quindi, applicacndo prima la Proprietà \ref{pro:prodeldet4} poi la
  Proprietà \ref{pro:prodeldet3}, si ottiene
  \begin{equation*}
    \det(A^\prime)=
    \begin{bmatrix}
      a_{11} & a_{12} & a_{13}\\
      a_{21} & a_{22} & a_{23}\\
      a_{31} & a_{32} & a_{33}
    \end{bmatrix} +
    \begin{bmatrix}
      a_{11} & a_{12} & a_{13}\\
      ca_{21} & ca_{22} & ca_{23}\\
      a_{31} & a_{32} & a_{33}
    \end{bmatrix}=\det(A)+c\begin{bmatrix}
      a_{11} & a_{12} & a_{13}\\
      a_{21} & a_{22} & a_{23}\\
      a_{31} & a_{32} & a_{33}
    \end{bmatrix}=\det(A)
  \end{equation*}
  tenuto conto che il determinante di una matrice con due righe uguali è
  nullo.
\end{pro}
\begin{pro}
  \label{pro:prodeldet8}
  Se sono nulli tutti gli elementi di una riga o di una colonna,
  $\det(A)=0$.
\end{pro}
\begin{es}
  \label{es:prodeldet6}
  Sviluppando la formula di Laplace sulla riga con tutti zeri, si vede
  che $\det(A)=0$
  \begin{equation*}
    \begin{bmatrix}
      1 & 2 & 3\\
      0 & 0 & 0\\
      -2 & 1 & -3
    \end{bmatrix} = -0
    \begin{bmatrix}
      2 & 3\\
      1 & -3
    \end{bmatrix}+ 0
    \begin{bmatrix}
      1 & 3\\
      -2 & -3
    \end{bmatrix}-0
    \begin{bmatrix}
      1 & 2 \\
      -2 & 1
    \end{bmatrix}= 0
  \end{equation*}
\end{es}
\begin{pro}
  \label{pro:prodeldet9}
  Il determinate di una matrice è nullo se e solo se una sue riga
  (o colonna) è combinazione lineare delle altre righe (o colonne).
  Segue dalle precedenti proprietà, infatti, supponendo che la terza riga
  sia combinazione lineare delle altre due
  \begin{eqnarray*}
    \begin{bmatrix}
      a_{11} & a_{12} & a_{13}\\
      a_{21} & a_{22} & a_{23}\\
      c_1a_{11}+c_2a_{21} & c_1a_{12}+c_2a_{22} & c_1a_{13}+c_2a_{23}
    \end{bmatrix}=\\
    \begin{bmatrix}
       a_{11} & a_{12} & a_{13}\\
      a_{21} & a_{22} & a_{23}\\
      c_1a_{11} & c_1a_{12} & c_1a_{13}
    \end{bmatrix}+\begin{bmatrix}
      a_{11} & a_{12} & a_{13}\\
      a_{21} & a_{22} & a_{23}\\
      c_2a_{21} & c_2a_{22} & c_2a_{23}
    \end{bmatrix}=\\c_1\cdot
    \begin{bmatrix}
      a_{11} & a_{12} & a_{13}\\
      a_{21} & a_{22} & a_{23}\\
      a_{31} & a_{32} & a_{33}\\
    \end{bmatrix}+c_2\cdot \begin{bmatrix}
      a_{11} & a_{12} & a_{13}\\
      a_{21} & a_{22} & a_{23}\\
      a_{31} & a_{32} & a_{33}\\
    \end{bmatrix}=0
  \end{eqnarray*}
  in quanto ci sono due righe uguali.
\end{pro}
\begin{es}
  \label{es:prodeldet8}
  Calcolatore il determinante della matrice, cercando di applicare le
  proprietà, in modo da semplificare il calcolo
  \begin{eqnarray*}
    \begin{bmatrix}
      ad+4 & c+7 & 4b+5 & 5a\\
      2b+1 & bc + 1 & b + 1 & a\\
      3d - 4 & -2d + 6 & bd+2 & 2a\\
      -2c & 3c & c & ac
    \end{bmatrix} & a,b,c,d \in \mathds{R}
  \end{eqnarray*}
\end{es}
\begin{proof}[Soluzione]
  \label{sol:prodeldet1}
  bisogna ricondursi al calcolo del determinante di una matrice
  triangolare
  \begin{equation*}
    abc^2
    \begin{bmatrix}
      ad & 1 & 4 & 5\\
      0 & b & 1 & 1 \\
      0 & 0 & d & 2\\
      0 & 0 & 0 & 1
    \end{bmatrix}=a^2b^2c^2d^2
  \end{equation*}
\end{proof}
Il concetto di matrice è di fondamentale importanza e compatirà in molti
contesti in questo corso. Nel contesto dei sistemi di equazioni lineari,
non solo la matrice completa costituisce una ``\emph{fotografia}'' fedele
di un sistemi e contiene tutte le informazioni necessarie a determinarlo,
ma sarà anche l'oggetto sul ci si focalizzerà all'interno del percorso.\\
Per motivi che verranno speficicati in seguito, sarà importante prendere
in considerazione anche la matrice che contiene solo i coefficienti delle
incognite, senza l'ultima colonna formata dai termini noti: si ottiene
così la cosiddetta \textit{matrice dei coefficienti del sistema}. Ad
esempio, la matrice dei coefficienti del sistema
(\ref{eq:matricediunsistlineare1}) è
\begin{equation}
  \label{eq:determinante2}
  \begin{pmatrix}
    1 & 3\\
    2 & -1
  \end{pmatrix}
\end{equation}
Ora, rappresentare un sistema mediante la sua matrice completa consente
di identiicare ogni sua equazione con una $n$-upla: la generica equazione,
diciarando la $i$-esima
\begin{equation}
  \label{eq:determinante3}
  a_{i1}x_1+a_{i2}x_2+\cdots+a_{in}x_n=b_i
\end{equation}
è rappresentata nella matrice completa dall'$i$-esima riga $R_i$
\begin{equation*}
  \begin{pmatrix}
    a_{i1} & a_{i2} & \cdots & a_{in} &b_i 
  \end{pmatrix}
\end{equation*}
e questa riga può a sua volta essere pensata come la $n+1$-upla
$\begin{pmatrix}
    a_{i1} & a_{i2} & \cdots & a_{in} &b_i 
\end{pmatrix}\in \mathds{K}^{n+1}$ (dove $\mathds{K}$ è campo dei
coefficienti delle equazioni). Queste corrispondenza è tale che qualunque
delle equazioni del sistema, corrisponde a una combinazione lineare delle
righe corrispondenti, viste come elementi di $\mathds{K}^{n+1}$, si
ottiene
\begin{equation*}
  c(a_{i1}x_1+a_{i2}x_2+\cdots+a_{in}x_n)=cb_{i}
\end{equation*}
ovvero, svolgendo i conti a primo membro, la nuova equazione
\begin{equation*}
  ca_{i1}x_1+ca_{i2}x_2+\cdots+ca_{in}x_n=cb_i
\end{equation*}
e tale equazione corrisponde alla $(x+1)-$upla
\begin{equation*}
  cR_i=(ca_{i1},ca_{i1_2},\cdots,ca_{in},cb_i)
\end{equation*}
ottenuta moltiplicando la $(n+1)-$uple
$R_i=(a_{i1},a_{i1_2},\cdots,a_{in},b_1)$ (che rappresenta l'equazione
originale) per $c$.\\
Allo stesso modo, se si sommano membro a membro l'equazione
(\ref{eq:determinante3}) per un'altra equazione
$a_{j1}x_1+a_{j2}+\cdots+a_{jn}x_{n}=b_j$ del sistema, si ottiene
\begin{equation*}
  a_{i1}x_1+a_{i2}+\cdots+a_{in}x_{n}+a_{j1}x_1+a_{j2}+\cdots+a_{jn}x_{n}
  =b_i+b_j
\end{equation*}
ovvero, raccoglendo gli addendi che contengono la stessa incognita, messa
in evidenza,
\begin{equation*}
  (a_{i1}+a_{j1})x_1+(a_{i2}+a_{j2})x_2+\cdots+(a_{in}+a_{jn})x_n=b_i+b_j
\end{equation*}
si ottiene una nuova equazione rappresentata dalla $n+1$-upla
\begin{equation*}
  R_i+R_j=(a_{i1}+a_{j1},a_{i2}+a_{j2},\cdots,a_{in}+a_{jn}b_i+b_j)
\end{equation*}
che si ottiene sommando le $n+1-$uple
$R_i=(a_{j1},a_{j2},\cdots,a_{jn},b_j)$ che rappresentavano le due
equazioni originali. Quindi, eseguendo più in generale una combinazione di
due o più equazioni di un sistema, rappresentate dalle righe
$R_1,R_2,\dots,R_m\in \mathds{K}^{n+1}$, l'equazione ottenuta
corrisponderà corrisponderà a una combinazione
\begin{equation*}
  c_1R_1+c_2R_2+\cdots+c_{in}R_{in}
\end{equation*}
delle righe corrispondenti.\\
Ad esempio, nel sistema (\ref{eq:eqlinematrici5}), se come visto in
(\ref{eq:eqlinematrici7}) moltiplicando (membro a membro) la prima
equazione per 5 e poi bisogna sommare alla seconda moltiplicata per $-3$,
ottenendo la nuova equazione $-x_2+2x_2+4x_3=-1$. Nella matrice completa
\begin{equation}
  \label{eq:determinante4}
  \begin{bmatrix}
    1 & 1 & 1 & 1\\
    2 & 1 & 3 & 2
  \end{bmatrix}
\end{equation}
l'operazione corrispondente non è nient'altro che la combinazione lineare
\begin{equation*}
  5R_1+(-3)R_2=5(1,1,1,1)+(-3)(2,1,3,2)=(-1,2,-4,-1)
\end{equation*}
delle sue due righe (viste come elementi di $\mathds{R}^4$).\\
Inoltre, se una terna $(x_1,x_2,x_3)$ soddisfa il sistema
(\ref{eq:eqlinematrici5}), essa soddisferà anche l'equazione
$-x_1+2x_2-4x_3=-1$, e in generale soddisferà tutte le possibile equazioni
che si corrispondono alle combinazioni lineari delle righe $R_1$ e $R_2$
della matrice completa.\\
In generale, dato un sistema di $m$ equazioni in $n$ incognite, con
matrice completa avente come righe $R_1,R_2,\dots,R_m$, una $n-$upla
$(x_1,x_2,\cdots,x_n)$ che soddisfa il sistema verifica anche tutte le
equazioni corrispondenti alle $(n+1)-$uple del tipo
$c_1R_1+c_2R_2+\cdots+c_mR_m$, ovvero quelle appartenenti al sottospazio
\begin{equation*}
  (R_1,R_2,\cdots,R_m)
\end{equation*}
generato dalle righe $R_1,R_2,\cdots,R_m$ (viste come elementi di
$\mathds{K}^{n+1}$), in quanto per definizione tale sottospazio è formato
proprio da tutte le combinazioni lineari $c_1R_1+c_2R_2+\cdots+c_mR_m$.\\
Da queste osservazioni si può dedurre il seguente riguente risultato, che
ci fornisce un criterio sufficiente perché due sistemi siano
\textit{equivalenti}, ovvero abbiano le stesse soluzioni:
\begin{prop}
  \label{prop:determinante1}
  Siano dati due sistemi di equazioni lineari in $n$ incognite, il
  primo con matrice completa formata dalle righe $R_1,R_2,\cdots,R_m$ e
  il secondo con matrice complate formata dalle righe
  $R_1,R_2,\cdots,R_i$. Se
  \begin{equation*}
    (R_1,R_2,\cdots,R_m)=(\bar{R_1},\bar{R_2},\cdots,\bar{R}_i)
  \end{equation*}
  allora i due sistemi sono equivalenti.
\end{prop}
\begin{proof}
  Se una $n-$upla $x=(x_1,x_2,\dots,x_n)$ è una soluzione del primo
  sistema, allora essa verifica tutte le sue equazioni, rappresentate
  dalle righe $R_1,R_2,\dots,R_m$ della sua matrice completa,
  rappresentate dalle sua matrice completa. Come osservato sopra, essa
  verifica allora anche tutte le equazioni corrispondenti alle
  $(n+1)$-upla uguale a $(\bar{R}_1,\bar{R}_2,\dots,\bar{R}_4)$, come
  affermato nell'ipotesi, $x$ verifica quindi tutte quindi tutte
  le equazioni corrispondenti alle $(n+1)-$uple del sottospazio
  $\left\langle \bar{R}_1,\bar{R}_2\dots,\bar{R}_4
\right\rangle$, e in
  particolare\footnote{All'interno del sottospazio $(v_1,v_2,\dots,v_n)$
    generato da un insieme di vettori e costituito come da tutte le
    combinazioni lineari $c_1v_1+c_2v_2+\dots+c_nv_n$ ci sono sempre
    anche i vettori $v_1,v_2,\dots,v_n$m stessi, in quanto ciascuno di
    loro può essere espresso come combinazione lineare:
    $v_1=1v_1+0v_2+\cdots+0v_n$, $v_2=0v_1+1v_2+\cdots+0v_n$, e così via.}
  $\bar{R}_1,\bar{R}_2,\dots,\bar{R}_4$, stesse, che rappresentano le
  equazioni del secondo sistema: quindi $x$ è soluzione anche del secondo
  sistema.\\
  Viceversa\footnote{Dimostrare che i due sistemi hanno le stesse
    soluzioni significa dimostrare che l'insieme delle soluzioni del
    primo è uguale all'insieme delle soluzioni del secondo, ovvero (come
    previsto dalla definizione di ugualianza di insiemi) che ogni
    $n$-upla che è soluzione del primo sistema è soluzione anche del
    secondo, e viceversa ogni $n$-upla soluzione del secondo sistema è
    anche soluzione del prima.}, se una $n$-upla $x=(x_1,x_2,\dots,x_n)$
  è una soluzione del secondo sistema, allora essa verifica tutte le sue
  equazioni, Quindi essa verifica allora anche tutte le equazioni
  corrispondenti alla $(n+1)-$uple contenute nel sottospazio $\left\langle
    \bar{R}_1,\bar{R}_2,\dots,R_t
  \right\rangle$. Essendo tale sottospazio uguale a $\left\langle
    R_1,R_2,\dots,R_m
  \right\rangle$, e in particolare $R_1,R_2,\dots,R_m$ stesse, che
  rappresentano le equazioni del primo sistema: quindi $x$ è soluzione
  anche del primo sistema.
\end{proof}
I metodo che useremo per risolvere un sistema, consiste proprio nel
trasformare il sistema dato in un sistema equivalente più semplice, nel
quale verranno eliminate tutte le equazioni superflue (che si ottengoo
come combinazione delle altre).

\section{L'algoritmo di eliminazione di Gauss-Jordan (o di riduzione a gradini)}
\label{sec:gauss-jordan}
Il metodo che vedremo ora per risolvere un qualunque sistema con $m$
equazioni lineari in $n$ incognite può essere spiegato come una
generalizzazione dei metodi tradizionalmente usati per la risoluzione dei
sistemi di due equazioni in due incognite. Per ricordare quali sono
questi metodi, prendiamo ad esempio il sistema
\begin{equation}
  \label{eq:gauss-jorda1}
  \begin{cases}
    x_1+x_2=0\\
    -x_1+x_2=1
  \end{cases}
\end{equation}
Solitamente, per risolvere tale sistema si ricava una delle incognite in
funzioni dell'altra usando una delle due equazioni, ad esempio dalla prima
equazione si trova $x_1=-x_2$, e si sostituisce l'espressione così
ottenuta nell'altra equazione:
\begin{equation*}
  -(-x_2)+x_2=1
\end{equation*}
ovvero
\begin{equation*}
  2x_2=1
\end{equation*}
In questo modo, è stato \emph{eliminato} la prima incognita dalla seconda
equazione che è diventata una semplice equazione di primo grado con una
sola incognita, che ha come soluzione $x_2=\frac{1}{2}$. A questo punto,
per ricavare $x_1$ basta sostituire il valore ottenuto di $x_2$ nella
prima equazione, ovvero
\begin{equation*}
  x_1+\frac{1}{2}=0 \to x_1=-\frac{1}{2}.
\end{equation*}
Quello che ha permesso di semplificare il sistema è stato quindi aver
ridotto il numero di incognite presenti in una delle equazioni. Allo
stesso risultato si può arrivare, equivalentemente, ad esempio sommando
membro a membro le due equazioni se $x_1+x_2=0$ e $-x_1+x_2=1$ allora
\begin{equation*}
  (x_1+x_2)+(-x_1+x_2)=0+1
\end{equation*}
ovvero, facendo i conti, si ottiene come sopra $2x_2=1$.\\
Questo secondo metodo, apparentemente più artificioso, in realtà si rivela
più semplice se si lavora sulla matrice completa del sistema invece, che
sulle equazioni. Infatti, la matrice completa del sistema
(\ref{eq:gauss-jorda1}) è
\begin{equation}
  \label{eq:gauss-jorda2}
  \begin{pmatrix}
    1 & 1 & 0\\
    -1 & 1 & 1
  \end{pmatrix}
\end{equation}
Sommare membro a membro le due equazioni equivale a sommare tra loro le
due: sostituendo poi tale somma alla seconda riga originale si ottiene,
senza dover maneggiare le incognite e dover fare sostituzioni o
semplificazioni.
\begin{equation}
  \label{eq:gauss-jorda3}
  \begin{pmatrix}
    1 & 1 & 0\\
    0 & 2 & 1
  \end{pmatrix}
\end{equation}
che corrisponde proprio al sitema ridotto
\begin{equation*}
  \begin{cases}
    x_1+x_2=0\\
    2x_2=1
  \end{cases}
\end{equation*}
risolvibile come visot sopra risolvendo prima l'equazione con una sola
incognita.\\
Questo stesso procedimento di eliminazione di incognite, realizzato
lavorando sulle righe della matrice completa, funziona in realtà per
risolvere qualunque sistema, qualunque sia il numero di equazioni e il
numero di incognite. Più precisamente, l'obbiettivo è avere il minor
numero numero di incognite possibile per garantire un risultato.\\
Se, per definire un criterio, si segne di eliminarle di seguito l'odine
$x_1,x_2,\dots, x_n$, questo significa che le righe della matrice completa
inizino con un numero sempre maggiore di zero.
\begin{equation*}
  \begin{pmatrix}
    1 & 1 & 1 & 1\\
    0 & 2 & 3 & 2\\
    0 & 0 & 4 & 5
  \end{pmatrix}
\end{equation*}
nella quale le righe iniziano con un numero sempre maggiore di zeri, ha
come sistema corrispondente
\begin{equation*}
  \begin{cases}
    x_1+x_2+x_3=1\\
    2x_2+2x_3=2\\
    4x_3=5
  \end{cases}
\end{equation*}
che ha la proprietà desiderata che le sue equazioni presentano un numero
decrescente di incognite.
Dopo questo è possibile rare la seguente
\begin{defi}
  \label{defi:gauss-jorda1}
  Una matrice si dice a gradini se, andando dalla prima all'ultima,
  ogni riga inizia con un numero sempre maggiore di zeri.\\
  Il primo elemento non nullo in ogni riga di una matrice a gradini si
  chiama \textit{pivot}.
\end{defi}
In altre parole, una matrice è a gradini se in ogni riga il primo elemento
non nullo compare con un indice di colonna sempre più grande. Ad esempio,
delle matrici seguenti
\begin{eqnarray*}
  \begin{pmatrix}
    7 & 1 & 1 & 3\\
    0 & 4 & 3 & 5\\
    0 & 0 & 0 & 6
  \end{pmatrix}, &
                   \begin{pmatrix}
                     7 & 1 & 1 & 3\\
                     0 & 1 & 3 & 5\\
                     0 & 2 & 0 & 6
                   \end{pmatrix}, &
                                   \begin{pmatrix}
                                     7 & 1 & 1 & 3\\
                                     0 & 0 & 3 & 5\\
                                     0 & 4 & 0 & 6
                                   \end{pmatrix}
\end{eqnarray*}
la prima è a gradini gradini perché i suoi pivot (7 nella prima riga,
4 nella seconda e 6 nella terza) si trovano, nell'ordine, sulla prima,
seconda e quarta colonna (indice di colonna sempre più grande), mentre
le altre no (nella seconda, il primo elemento non nullo della terza riga
sta nella stessa colonna del primo elemento non nullo della seconda riga;
nella terza matrice, il primo elemento non nullo della terza riga sta in
una colonna di indice più piccolo del primo elemento non nullo della
seconda riga). Un sistema si dice a gradini se la sua matrice completa è
una matrice a gradini.\\
Il procedimento che desscritto qui di seguito è chiamato \textit{metodo
  di riduzione a gradini} o, dal momento che consiste nell'eliminare
incognite, \textit{metodo di eliminazione di Gauss-Jordan}.\\
Il procedimento di riduione a gradoni, oltre a semplificare il sistema, fa
emergere anche le eventuali incompatibilità e le eventuali equazioni
superflue presenti nel sistema.\\
Per trasformare un sistema in un sistema a gradini, trasformeremo la sua
matrice completa in una matrice a gradini tramite le seguenti operazioni
slle sue righe, dette \textit{operazioni elementari di primo, secondo
  terzo tipo}:
\begin{description}
\item[primo tipo] Scambiare tra loro due righe della matrice (
  $R_i \leftrightarrow R_j$)
\item[secondo tipo] Moltiplicare una riga della matrice per un
  coefficiente non nullo ($R_i\to cR_i$, con $c\neq 0$)
\item[terzo tipo] Sommare a una riga della matrice un'altra riga
  moltiplicata per un mumero qualunque ($R_i=R_i+dR_j$)
\end{description}
Il fatto importante è che tali operazioni, che modificano le righe,
corrispondono a modificare le equazioni del sistema \textit{in modo però
  da non combiare l'insieme delle soluzioni,} come dimostra il seguente
risultato, corollario delle Proposizione \ref{prop:determinante1}:
\begin{prop}
  \label{prop:determinante2}
  Se viene effettuate operazioni elementari di primo, secondo e terzo
  tipo sulla matrice completa di un sistema, la matrice trasformeta è la
  matrice completa di un sistema \textit{equivalente} a quello iniziale
  (ovvero avente le stesse soluzioni del sistema iniziale).
\end{prop}
Dopo questo, verrà illustrato come mediante l'uso delle tre operazioni
elementari, ogni sistema possa essere trasformato in un sistema a gradini:
sia
\begin{equation}
  \label{eq:gauss-jorda4}
  A=
  \begin{pmatrix}
    a_{11} & a_{12} & \cdots & a_{1n} & b_1\\
    a_{21} & a_{22} & \cdots & a_{2n} & b_2\\
    a_{31} & a_{32} & \cdots & a_{3n} & b_3\\
    \vdots & \vdots & \vdots & \vdots\\
    a_{m1} & a_{m2} & \cdots & a_{mn} & b_m
  \end{pmatrix}
\end{equation}
La matrice completa del generico sistema (\ref{eq:eqlinematrici2}).\\
L'algoritmo inizia come segue: se la prima entrata $a_{11}$ della prima
riga è uguale a zero, le si scambia tra loro nelle due righe (applicando
quindi un'operazione elementare del primo tipo) in modo da garantire che
la nuova entrata $a_{11}$ sia diversa da zero. Fatto ciò, si applica alla
matrice (\ref{eq:gauss-jorda4}) le seguenti operazioni elementari (del
terzo tipo) sulle righe $R_2,\dots,R_m$ dalla seconda all'ultima:
\begin{equation*}
  \begin{matrix}
    R_2\to R_2-\frac{a_{21}}{a_{11}}R_1\\
    R_{3}\to R_3-\frac{a_{31}}{a_{11}}R_1\\
    \vdots\\
    R_{m}\to R_m-\frac{a_{m1}}{a_{11}}R_1
  \end{matrix}
\end{equation*}
(si noti che le operazioni si possono applicare proprio perché
$a_{11}\neq 0$). Queste trasformazioni rendono sicuramente uguale a zero
la prima entrata di ogni riga dalla secomnda in poi, e eventualmente
potrebbero aver annullato anche altre entrate, ovvero trasformano la
matrice (\ref{eq:gauss-jorda4}) in una matrice seguente tipo
\begin{equation}
  \label{eq:gauss-jorda5}
  \begin{pmatrix}
    a_{11} & \dots & \dots & \dots & \dots & a_{1n} & b_1\\
    0 & \dots & 0 & a_{2k}^\prime & \dots & a_{2n}^\prime & b_2^\prime\\
    0 & \dots & 0 & a_{3k}^\prime & \dots & a_{3n}^\prime & b_3^\prime\\
           & \cdots\\
    0 & \dots & 0 & a_{mk}^\prime & \dots & a_{mn}^\prime & b_m^\prime
  \end{pmatrix}
\end{equation}
si può supporre che la siconda rica sia quella che inizia con il minor
numero di zeri, con $a_{2k}^\prime\neq 0$. A questo punto, si ripete quanto
fatto nella prima parte della trasformazione, applicando stavolta alle
righe dalla terza in poi le trasformazioni elementari del terzo tipo
\begin{equation*}
  \begin{matrix}
    R_3\to R_3-\frac{a^\prime_{3k}}{a_{2k}^\prime}R_2\\
    \vdots\\
    R_m\to R_m-\frac{a^\prime_{mk}}{a_{2k}^\prime}R_2\\
  \end{matrix}
\end{equation*}
che sono tali da annullare la prima entrata non nulla dalla terza riga in
poi, ovvero da trasformare la matrice in una matrice del tipo
\begin{equation}
  \label{eq:gauss-jorda6}
  \begin{pmatrix}
    a_{11} & \dots & \dots & \dots & \dots & a_{1n} & b_1\\
    0 & \dots & 0 & a_{2k}^\prime & \dots & a_{2n}^\prime & b_2^\prime\\
    0 & \dots & 0 & 0 & \dots & a_{3n}^{\prime\prime} & b_3^{\prime\prime} \\
           &\dots\\
    0 & \dots & 0 & 0 & \dots & a_{mn}^{\prime\prime} & b_{m}^{\prime\prime}
  \end{pmatrix}
\end{equation}
In questo modo si può trasformare la matrice del sitema in una matrice
ogni riga inizia con un numero sempre maggiore di zeri, ovvero nella
matrice a gradini voluta, e il sistema corrispondente sarà equivalente al
sistema iniziale in quanto la trasmissione è stata effettuata con
operazioni elementari. Il modo migliore di capire questo procedimento è
con un esempio.
\begin{es}
  \label{es:gauss-jorda1}
  Sia
  \begin{equation}
    \label{eq:gauss-jorda1-1}
    \begin{cases}
      x_1+x_2+x_3=1\\
      -x_1+x_2-x_3=0\\
      -x_1+x_2+x_3=-3
    \end{cases}
  \end{equation}
  il sistema con matrice completa
  \begin{equation}
    \label{eq:gauss-jorda1-2}
    \left(
      \begin{array}{ccc|c}
        1 & 1 & 1 & 1\\
        -1 & 1 & -3 & 0\\
        -1 & 1 & 1 & -3
      \end{array}\right)
  \end{equation}
  Ora, è possibile trasformare tale matrice in una matrice a gradini
  usando le operazioni elementari, in modo da ottenere un sistema a
  gradini equavalente al sistema (\ref{eq:gauss-jorda1-1}).\\ Ricordando
  che, in base alla definizione di matrice a gradini, visto che il primo
  elemento $a_{11}$ della prima riga è diverso da zero, e sta nella prima
  colonna, i primi elementi diversi da zero della seconda e della terza
  riga non possono essere anche loro nella prima colonna: in altre parole,
  è mecessario trasformare la matrice in modo che $a_{21}$ e $a_{31}$
  siano uguali a zero.\\
  Ottenendo sicuramente lo scopo se si applicano anche le operazioni
  elementari del terzo tipo $R_2\to R_2+R_1$ e $R_3\to R_3+R_1$: infatti,
  \begin{eqnarray*}
    \left(
      \begin{array}{ccc|c}
        1 & 1 & 1 & 1\\
        -1 & 1 & -3 & 0\\
        -1 & 1 & 1 & -3
      \end{array}\right)& \overrightarrow{
        \begin{matrix}
          R_2\to R_2+R_1\\
          R_3\to R_3+R_1
        \end{matrix}
      }& \left(
        \begin{array}{ccc|c}
          1 & 1 & 1 & 1\\
          0 & 2 & -2 & 1\\
          0 & 2 & 2 & -2
        \end{array}\right)
  \end{eqnarray*}
  La matrice trasformata non è ancora una matrice a gradini in quanto il
  primo elemento non nullo della terza riga si trova in corrispondenza
  della stessa colonna (la seconda) del primo elemento non nullo nella
  seconda riga: è decessario che $a_{32} = 0$ (diventi nullo). A questo
  scopo, basta applicare l'operazione elementare $R_3\to R_3-R_2$:
  così facendo si ottiene
  \begin{eqnarray*}
    \left(
        \begin{array}{ccc|c}
          1 & 1 & 1 & 1\\
          0 & 2 & -2 & 1\\
          0 & 2 & 2 & -2
        \end{array}\right) & \overrightarrow{
                             R_3\to R_3-R_2} &
                                               \left(
        \begin{array}{ccc|c}
          1 & 1 & 1 & 1\\
          0 & 2 & -2 & 1\\
          0 & 0 & 4 & -3
        \end{array}\right)
  \end{eqnarray*}
  E alla fine di questo processo si otterà come sistema:
  \begin{equation}
    \label{eq:gauss-jorda1-3}
    \begin{cases}
      x_1+x_2+x_3=1\\
      2x_2+2x_3=1\\
      4x_3=-3
    \end{cases}
  \end{equation}
  corrispondente alla matrice trasformata è, equivalente al sistema
  originale (\ref{eq:gauss-jorda1-1}), quindi trovando la sua risoluzione
  trovando la soluzione del sistema (\ref{eq:gauss-jorda1-1}).
  \begin{equation*}
    2x_2-2x_3=1\to 2x_2=1+2x_3=1+2\left(-\frac{3}{4}\right)=1-\frac{3}{2}
    =-\frac{1}{2} \to x_2=-\frac{1}{4}
  \end{equation*}
  e analogamente, sostituendo i valori di $x_2$ e $x_3$ così ottenuti
  nella prima equazione si trova
  \begin{equation*}
    x_1+x_2+x_3=1\to x_1=1-x_2-x_3= 1 - \left(-\frac{1}{4}\right)-\left(-
      \frac{3}{4}\right)=2
  \end{equation*}
  Avendo quindi la terna $
  \begin{pmatrix}
    2, & -\frac{1}{4}, & -\frac{3}{4}
  \end{pmatrix}
  $ è l'unica soluzione del sistema (\ref{eq:gauss-jorda1-3}), ovvero
  del sistema iniziale (\ref{eq:gauss-jorda1-1}).
\end{es}
La riduzione a gradini non solo semplifica il sitema grazie alla
eliminazione di incognite, ma mette anche in evidenza eventuali
``equazioni superflue'' e incompatibilità tra le equazioni.
\begin{es}
  \label{es:gauss-jorda2}
  Considerando il sistema
  \begin{equation}
    \label{eq:gauss-jorda2-1}
    \begin{cases}
      x_1+x_2+x_3=1\\
      x_1-x_2-x_3=0\\
      x_1+3x_2+3x_3=1
    \end{cases}
  \end{equation}
  che ha come matrice completa
  \begin{equation}
    \label{eq:gauss-jorda2-2}
    \left(\begin{array}{ccc|c}
      1 & 1 & 1 & 1   \\
      1 & -1 & -1 & 0 \\
      1 & 3 & 3 & 1
    \end{array}\right)
  \end{equation}
  Come fatto per il sistema precedente, trasformando tale matrice in una
  matrice a gradini mediante operazioni elementari.
  \begin{eqnarray*}
    \left(\begin{array}{ccc|c}
      1 & 1 & 1 & 1   \\
      1 & -1 & -1 & 0 \\
      1 & 3 & 3 & 1
    \end{array}\right)& \overrightarrow{
        \begin{matrix}
          R_2\to R_2+R_1\\
          R_3\to R_3+R_1
        \end{matrix}
      }& \left(\begin{array}{ccc|c}
        1 & 1 & 1 & 1   \\
        1 & -2 & -2 & -1 \\
        0 & 2 & 2 & 0
      \end{array}\right)\\
    \left(\begin{array}{ccc|c}
        1 & 1 & 1 & 1   \\
        1 & -2 & -2 & -1 \\
        0 & 2 & 2 & 0
      \end{array}\right) & \overrightarrow{
                             R_3\to R_3-R_2} &
                              \left(\begin{array}{ccc|c}
                                1 & 1 & 1 & 1   \\
                                0 & -2 & -2 & -1 \\
                                0 & 0 & 0 & -1
                              \end{array}\right)
  \end{eqnarray*}
  Notare che la terza riga dalla matrice trasformata corrisponde
  all'equazione $0x_1+0x_2+0x_3=-1$, ovvero $0=-1$: poiché questa
  uguaglianza è falza, non esiste nessuna terna che soddisfi le tre
  condizioni del sistema ridotto corrispondente, ovvero tale sistema non
  ha soluzioni. Questo, in virtù dell'equivalenza tra il sistema originale
  e quello ridotto, questo indica che il sistema di partenza non ha
  soluzioni, ovvero è incompatibile.\\
  Evidentemente tra le equazioni del sistema di partenza vi era una
  incompatibilità non evidente che il procedimento di riduzione a gradini
  ha fatto emergere: infatti, se si moltiplica membro a membro la prima
  equazione per 2 e si sottrae la seconda equazione si ottiene
  \begin{eqnarray*}
    2(x_1+x_2+x_3)-(x_1-x_2-x_3)=2\cdot 1 - 0
  \end{eqnarray*}
  ovvero, svolgendo i calcoli, $x_1+3x_2+3x_3=2$. Quasta condizione, che è
  conseguenza delle prime due equazioni ed è quindi soddisfatta da
  qualunque terna le soddisfi, è chiaramente incompatibile con la terza
  equazione; il procedimento di riduzione a gradini ha messo alla luce
  questa incompatibilità trasformandola nell'incompatibilità evidente
  $0=-1$.\\
  Considerando ora come ultimo esempio il sistema
  \begin{equation}
    \label{eq:gauss-jorda2-3}
    \begin{cases}
      x_1+x_2+3x_3=1\\
      x_1-2x_2+x_3=0\\
      x_1-5x_2-x_3=-1
    \end{cases}
  \end{equation}
  che ha come matrice completa
  \begin{equation}
    \label{eq:gauss-jorda2-4}
    \left(
      \begin{array}{ccc|c}
        1 & 1 & 3 & 1\\
        1 & -2 & 1 & 0\\
        1 & -5 & -1 & -1
      \end{array}\right)
    \end{equation}
    Applicando operazioni elementari per ridurre a gradini,
    \begin{eqnarray}
      \label{eq:gauss-jorda2-4}
      \left(
      \begin{array}{ccc|c}
        1 & 1 & 3 & 1\\
        1 & -2 & 1 & 0\\
        1 & -5 & -1 & -1
      \end{array}\right) & \overrightarrow{
        \begin{matrix}
          R_2\to R_2+R_1\\
          R_3\to R_3+R_1
        \end{matrix}
      }& \left(
      \begin{array}{ccc|c}
        1 & 1 & 3 & 1\\
        0 & -3 & -2 & -1\\
        0 & -6 & -4 & -2
      \end{array}\right)\\
       \left(
       \begin{array}{ccc|c}
         1 & 1 & 3 & 1\\
         0 & -3 & -2 & -1\\
         0 & -6 & -4 & -2
       \end{array}\right) & \overrightarrow{
                             R_3\to R_3-R_2} &
                              \left(
      \begin{array}{ccc|c}
        1 & 1 & 3 & 1\\
        0 & -3 & -2 & -1\\
        0 & 0 & 0 & 0
      \end{array}\right)
    \end{eqnarray}
    In questo caso avviene un qualcosa di particolare, infatti, la terza
    equazione del sistema si annulla come, si evince dalla
    $0x_1+0x_2+0x_3 = 0$, ovvero $0 = 0$.\\
    Quindi trasformando da matrice a sistema
    \begin{equation}
      \label{eq:gauss-jorda2-5}
      \begin{cases}
        x_1+x_2+3x_3=1\\
        -3x_2-2x_3=-1
      \end{cases}
    \end{equation}
    Benché non sia rimasta un'equazione con una sola incognita come nel
    primo sistema appena risolto, è possibile comunque progedere
    nel seguente modo:\\
    Bisogna ricavare $x_2$ dalla seconda equazione:
    \begin{equation}
      \label{eq:gauss-jorda2-6}
      -3x_2-2x_3=-1\to -3x_2=2x_3-1=-\frac{2}{3}x_3+\frac{1}{3}
    \end{equation}
    e sostituendo l'espressione ottenuta nella prima equazione per
    ricavare $x_1$:
    \begin{equation}
      \label{eq:gauss-jorda2-7}
      x_1+x_2+3x_3=1\to x_1=1-x_2-x_3=1-\left(9\frac{2}{3}x_3+\frac{1}{3}
        \right)-3x_3=\frac{2}{3}-\frac{7}{3}x_3.
    \end{equation}
    Ora, qualunque valore $t\in \mathds{R}$ assegnando a $x_3$, la
    (\ref{eq:gauss-jorda2-6}) e la (\ref{eq:gauss-jorda2-7}) dice che se
    si pone $x_2=-\frac{2}{3}t+\frac{1}{3}$ e
    $x_1=\frac{2}{3}-\frac{7}{3}t$, le equazioni del sistema saranno
    soddisfatte, ovvero si otterrà una soluzione. Espresso in altri
    termini, le soluzioni del sistema sono esattamente tutte le terne
    del tipo $\left(\frac{2}{3}-\frac{7}{3}t, -\frac{2}{3}t+\frac{1}{3},t
    \right)$ al variare di $t\in \mathds{R}$: il sistema ha quindi
    infinite soluzioni.\\
    Più precisamente, dal momento che le infinite
    soluzioni del sistema dipendono da un solo parametro libero $t$, si
    dice che il sistema ha ``infinito alla uno'' (si scrive $\infty^1$)
    soluzioni.
\end{es}
In genere, è possibile dare la seguente
\begin{defi}
  \label{defi:gauss-jorda1}
  Un sistema di equazioni lineari ha $\infty^k$ soluzioni se
  l'espressione generale della sua soluzione dipende da $k$ parametri
  liberi.
\end{defi}
Nell'ultimo esempio esposto, la riduzione ha eliminato delle tre
equazioni del sistema riducendola all'identità $0=0$. In effetti, non è
difficile vedere che la terza equazione $x_1-5x_2-x_3=-1$ era un'equazione
``superflua'', o più precisamente dipendente dalle altre due: come si
vede nella matrice completa (\ref{eq:gauss-jorda2-4}), la terza riga, che
la rappresenta, è combinazione delle altre due:
\begin{equation*}
  (1,-5,-1,-1)=-(1,1,3,1)+2(1,-2,1,0)
\end{equation*}
In effetti, non è difficile vedere che una matrice a gradini, escluse le
righe nulle, non ha più righe dipendenti (e quindi le equazioni non
nulle di un sistema ridotto a gradini sono sicuramente indipendenti):
\begin{prop}
  \label{prop:gauss-jorda1}
  Le righe non nulle di una matrice ridotta a gradini sono
  linearmente indipendenti
\end{prop}
\begin{proof}
  Per definizione di matrice a gradini le sue righe saranno del tipo
  \begin{eqnarray*}
    R_1=(a_{11},\dots), & a_{11}\neq0\\
    R_2=(0,\dots, 0, a_{2k},\dots,), & a_{2k}\neq 0\\
    R_3=(0,\dots,0,0,\dots,0,a_{3j},\dots,), & a_{3j}\neq 0\\
    \vdots
  \end{eqnarray*}
  con $k>1,j>k$ etc, ovvero in ogni riga il primo elemento non nullo
  compare via via con secondo indice sempre più grande.\\
  Ora, per dimostrare che tali righe sono indipendenti basta supporre che
  tali righe sono indipendenti basta supporre che
  \begin{equation}
    \label{eq:gauss-jorda3}
    c_1(a_{11},\dots)+c_2(0,\dots,0,a_{2k},\dots,)+c_3(0,\dots,0,0,\dots,
    0,a_{3j},\dots,)+\dots=(0,\dots,0)
  \end{equation}
  e dimostrare che i coefficinti $c_1,c_2,c_3$, etc. Devono essere
  necessariamente tutte nulli.\\
  Andando a guardare cosa significa l'uguaglianza (\ref{eq:gauss-jorda3})
  vedendo che nella prima entrata rimane solo $c_1a_{11}=0$: ma, essendo
  per ipotesi $a_{11}\neq 0$, necessariamente deve essere $c_1=0$. Quindi,
  la (\ref{eq:gauss-jorda3}) si riduce a
  \begin{equation}
    \label{eq:guess-jorda4}
    c_2(0,\dots,0,a_{2k},\dots,)+c_3(0,\dots,0,0,\dots,a_{3j},\dots,)+
    \dots= (0,\dots,0)
  \end{equation}
  Ora, guardando la $k$-esima entrata di questa relazione (cioè la prima
  diversa da zero nella seconda riga): dal momento che tutte le righe
  successive alla seconda hanno la prima entrata diversa da zero con
  indice più alto, si ottiene $c_2a_{2k}=0$, che, essendo $a_{2k}\neq 0$,
  dice che $c_2=0$.\\
  Dunque la (\ref{eq:guess-jorda4}) si riduce a
  \begin{equation*}
    c_3(0,\dots,0,9,\dots,a_{3j},\dots,)+\dots=(0,\dots,0)
  \end{equation*}
  e, continuando a ragionare in questo modo, si vedranno tutti i
  coefficenti $c_i$ si devono annullare, e quindi non può esistere una
  combinazione lineare delle righe uguale al vettore nullo e con
  coefficienti non tutti nulli, ovvero le righe sono indipendenti.
\end{proof}
\begin{oss}
  \label{oss:guess-jorda1}
  Quando si effettua delle operazioni elementari sulle righe di una
  matrice, si può considerare anche le trasformazioni del tipo $R_i\to
  cR_i+dR_{j}$, purché il coefficiente $c$ per cui bisogna moltiplicare
  la riga $R_i$ in modo che sostituendo non sia zero: infatti, benché
  tale traormazione non sia una delle tre operazioni elementari, essa
  può essere pensata come il risultato dell'applicando alla riga $R_i$
  l'operazione elementare del secondo tipo $R_i\to cR_i$ (con $c\neq 0$
  come previsto) e poi applicando alla nuova riga $cR_i$ così ottenuta
  l'operazione elementatre del terzo tipo $cR_i=cR_i+dR_j$.
\end{oss}
Il procedimento di riduzione a gradini, che è stato utilizzato come
strumento di risoluzione di un sistema, in realtà è sostanzialmente un
motodo che stabilisce se dei vettori sono indipendenti. Infatti, più
precisamente, si riscontrano i seguenti fatti:
\begin{enumerate}
\item Il procedimento non modifica lo spazio generato dalle righe, ovvero
  se $R_1,R_2,\dots,R_m$ sono le righe della matrice iniziale, e
  $\bar{R}_1,\bar{R}_2,\dots,\bar{R}_m$ sono le righe della matrice
  trasformata, allora $(R_1,R_2,\dots,R_m)=(\bar{R}_1,\bar{R}_2,\dots,
  \bar{R}_m)$;
\item le righe non nulle alla fine del procedimento formano un insieme di
  vettori indipendenti.
\end{enumerate}
Quindi, se le righe non nulle dopo la riduzione sono le prime $l$, ovvero
$\bar{R}_1,\bar{R}_2,\dots,R_i$, dal fatto che queste sono indipendenti
deducendo che consituiscono una base del sottospazio da loro generato, e
quindi
\begin{equation*}
  \dim(\bar{R_1},\bar{R_2},\bar{R_i})=l;
\end{equation*}
ma poiché il sottospazio generato non cambia, si può concludere che
\begin{equation*}
  \dim(R_1,R_2,R_m)=l.
\end{equation*}
Il numero di righe non nulle rimaste dopo la riduzione a gradini ci dà
quindi la dimensione dello spazio generato dalle righe iniziali: in uno
spazio di dimensione $l$ ci sono al massimo $l$ vettori indipendenti, e
le restanti di righe non nulle rimaste dopo la riduzione dimostra che
quante righe indipendenti  aveva la matrice prima della riduzione. Questa
informazione, giustifica la seguente
\begin{defi}
  \label{defi:gauss-jorda2}
  Il massimo numero di righe indipendenti di una matrice $A$ si
  chiama il \textit{rango per righe} di $A$.\\
  Quindi la riduzione a gradini definisce un modo per calcolare la
  dimensione di uno spazio e per definizione di uno spazio e per
  verificare se delle $n$-uple date siano indipendenti.\\
  Ad esempio, considerando le seguenti 4-uple
  \begin{equation}
    \label{eq:gauss-jorda2-1}
    \begin{matrix}
      (1,1,2,1,), & (1,2,1,0), & (1,-1,4,3), & (2,1,1,0)
    \end{matrix} 
  \end{equation}
  vedendo di determinare se esse siano o meno indipendenti. Disponendo
  4-uple a formare le righe di una matrice
  \begin{equation*}
    \begin{bmatrix}
      1 & 1 & 2 & 1\\
      1 & 2 & 1 & 0\\
      1 & -1 & 4 & 3\\
      2 & 1 & 1 & 0
    \end{bmatrix}
  \end{equation*}
  riduciendo a gradini seguendo il procedimeto di eliminazione (come
  definito nei paragrafi precedenti)
  \begin{equation}
    \label{eq:gauss-jorda2-2}
    \begin{matrix}
      \begin{bmatrix}
        1 & 1 & 2 & 1\\
        1 & 2 & 1 & 0\\
        1 & -1 & 4 & 3\\
        2 & 1 & 1 & 0
      \end{bmatrix}
      \overrightarrow{
      \begin{matrix}
        R_2\to R_2-R_1\\
        R_3\to R_3-R_1\\
        R_4\to R_4-2R_1
      \end{matrix}
      }
      \begin{bmatrix}
        1 & 1 & 2 & 1\\
        0 & 1 & -1 & -1\\
        0 & -2 & 2 & 2\\
        0 & -1 & -3 & -2
      \end{bmatrix}
      \overrightarrow{
      \begin{matrix}
        R_3\to R_3+2R_2\\
        R_4\to R_4+R_2
      \end{matrix}
      }
      \begin{bmatrix}
        1 & 1 & 2 & 1\\
        0 & 1 & -1 & -1\\
        0 & 0 & 0 & 0\\
        0 & 0 & -4 & -3
      \end{bmatrix}\\
      \overrightarrow{
      R_4\leftrightarrow R_3}
      \begin{bmatrix}
        1 & 1 & 2 & 1\\
        0 & 1 & -1 & -1 \\
        0 & 0 & -4 & -3\\
        0 & 0 & 0 & 0
      \end{bmatrix}
    \end{matrix}
  \end{equation}
  l'ultimo scambio di righe è stato necessario per portare la matrice
  nella forma a gradini.\\
  Dopo la riduzione sono la riduzione sono rimaste 3 righe nulle, ovvero
  il rango della matrice è 3: nell'insieme iniziale vi erano allora 3
  righe indipendenti e una quarta dipendente dalle altre (quindi le
  4-uple non erano linearmente indipendenti).\\
  In particolare, è possibile affermare che il vettore da escludere se
  si vuole estrarre un insieme di vettori indipendenti dai quattro
  vettori dati era il terzo, \textit{corrispondente alla riga annullata
    dalla riduzione}. Infatti, per arrivare all'annullamento di tale riga
  in primo luogo è stato eseguito $R_2\to R_2-R_1$ e $R_3\to R_3-R_1$, e
  poi sommando alla (ottenuta) terza riga $R_3-R_1$ la (ottenuta) seconda
  riga $R_2-R_1$ moltiplicata per 2, ovvero
  \begin{equation*}
    (R_3-R_1)+2(R_2-R_1)=0
  \end{equation*}
  Svolgendo i conti, questa uguaglianza dice che $R_3-3R_1+2R_2=0$, ovvero
  \begin{equation*}
    R_3=3R_1-2R_2
  \end{equation*}
  che conferma che la terza riga è scrivibile come combinazione delle
  altre. Il fatto appena illustrato in questo è vero in genere: se una
  riga si annula in seguito all'algoritmo di riduzione a gradini allora
  essa era esprimibile come combinazione delle altre. Infatti, nel corso
  delle riduzione a gradini bisogna trasformare da prima tutte tutte le
  righe dalla seconda in poi combinandole con la prima
  \begin{equation*}
    \begin{matrix}
      R_2\to R_2+c_2R_1, & R_3\to R_3+c_3R_1,\dots,R_m \to R_m+c_mR_1
    \end{matrix}
  \end{equation*}
  Ne secondo passaggio, ogni riga così trasformata viene combinata con la
  seconda riga:
  \begin{equation*}
    R_k\to (R_k+c_kR_1)+c_k^\prime(R_2+c_2R_!)=R_k+(c_kc^\prime_kc_2)R_1
    +c_k^\prime R_2
  \end{equation*}
  e così via: a ogni passaggio la riga $R_k$ viene combinata con una in
  più delle righe precedenti, fino a che o non bisogna più modificarlo
  perché si inizia ad utilizzarla per ridurre le successive, oppure essa
  si annulla: in tal caso si arriva quindi a una relazione del tipo:
  \begin{equation*}
    R_k+d_1R_1+d_2R_2+\dots+d_jR_j=0
  \end{equation*}
  ovvero $R_k=-d_1R_1-d_2R_2-\dots-d_jR_j$, che dice che la riga $R_k$ che
  si è annullata era combinazione lineare delle altre righe.
\end{defi}
\begin{oss}
  \label{oss:gauss-jorda3}
  l'affermazione secondo cui le righe che si annullano sono combinazione
  lineare delle altre è vera quando si segue l'algoritmo di riduzione
  a gradini, ma in generale se una riga si annulla dopo una serie
  qualunque di operazioni elementari non è detto che sia combinazione
  lineare delle altre. Ad esempio, si consideri la seguente sequenza di
  operazioni elementari (che non segue i passi dell'algoritmo di
  riduzione a gradini)
  \begin{eqnarray*}
    \begin{bmatrix}
      1 & 0\\
      2 & 0\\
      0 & 1
    \end{bmatrix} \overrightarrow{
      R_3\to R_3+R_1
    }
    \begin{bmatrix}
      1 & 0 \\
      2 & 0 \\
      1 & 1
    \end{bmatrix}
    \overrightarrow{R_2\to R_2+R_3}
    \begin{bmatrix}
      1 & 0\\
      3 & 1\\
      1 & 1
    \end{bmatrix}\overrightarrow{R_3\to R_3-R_2}
    \begin{bmatrix}
      1 & 0 \\
      3 & 1 \\
      -2 & 0
    \end{bmatrix}\\
    \overrightarrow{R_3\to R_3+2R_1}
    \begin{bmatrix}
      1 & 0\\
      3 & 1\\
      0 & 0
    \end{bmatrix}
  \end{eqnarray*}
  a seguito della quale la terza riga si anulla, pur non essendo
  combinazione lineare delle altre: non c'è nessun modo di esprimere
  (0,1) come combinazione di (1,0) e (2,0)\footnote{si noti che non sono
    stati fatti scambi di riga}.\\
  La Definizione \ref{defi:gauss-jorda2} suggerisce che si può definire
  anche il \textit{rango per colonne} di una matrice come il numero
  massimo di colonne linearmente indipendenti\footnote{ovvero la
    dimensione dello spazio generato dalle colonne}. Tuttavia vale la
  seguente
\end{oss}
\begin{prop}
  \label{prop:gauss-jorda2}
  Per una qualunque matrice, il rango per righe coincide con il
  rango per colonne.\\
  Non dimostrando la proposizione \ref{prop:gauss-jorda2}, ma è possibile
  illustrarla con un semplice esempio: nella matrice
  \begin{equation*}
    \begin{bmatrix}
      1 & 1 & 1\\
      2 & 2 & 2\\
      3 & 4 & 5
    \end{bmatrix}
  \end{equation*}
  la seconda riga $R_2$ è evidentemente dipendente dalle altre, in quanto
  $R_2=2R_1$ (se si volesse far apparire anche la terza riga in questa
  relazione di dipendenza, si potra scrivere $R_2=2R_1+0R_3$).
  Per il risultato appena citato, allora anche una delle colonne della
  matrice deve essere dipendente dalle altre: in effetti, si ha
  \begin{equation*}
    \begin{bmatrix}
      1 \\
      2\\
      5
    \end{bmatrix}=2 \cdot
    \begin{bmatrix}
      1 \\
      2\\
      4
    \end{bmatrix}-
    \begin{bmatrix}
      1\\
      2\\
      3
    \end{bmatrix},
  \end{equation*}
  che era molto meno evidente della relazione di dipendenza esistente tra
  righe. Come ulteriore esempio, si considerino le stesse $4-$uple viste
  sopra in (\ref{eq:gauss-jorda2-1}): grazie all'uguaglianza del rango
  del rango per righe e per colonne, in effetti i vettori possono essere
  disposti sia in colona che in riga, l'importante è scegliere se tutti
  i vettori devono essere disposti in un o nell'altro modo.
  \begin{equation*}
    \begin{bmatrix}
      1 & 1 & 1 & 2\\
      1 & 2 & -1 & 1 \\
      2 & 1 & 4 & 1 \\
      1 & 0 & 3 & 0
    \end{bmatrix}
  \end{equation*}
\end{prop}
Il rango per righe di questa matrice, che possono essere calcolate con il
procedimento di riduzione a gradini, è quindi uguale al rango per colone
della precedente, ovvero deve sempre essere uguale a 3. Infatti
\begin{equation}
  \label{eq:guess-jorda5}
  \begin{matrix}
    \begin{bmatrix}
      1 & 1 & 1& 2\\
      1 & 2 & -1 & 1\\
      2 & 1 & 4 & 1\\
      1 & 0 & 3 & 0
    \end{bmatrix}
    \overrightarrow{
    \begin{matrix}
      R_2\to R_2- R_1\\
      R_3\to R_3-2R_1\\
      R_3\to R_4-R_1
    \end{matrix}
    }
    \begin{bmatrix}
      1 & 1 & 1 & 2\\
      0 & 1 & -2 & -1 \\
      0 & -1 & 2 & -3\\
      0 & -1 & 2 & -2
    \end{bmatrix}
    \overrightarrow{
    \begin{matrix}
      R_3\to R_3+R_2\\
      R_4\to R_4+R_2
    \end{matrix}
    }
    \begin{bmatrix}
      1 & 1 & 1 & 2\\
      0 & 1 & -2 & -1\\
      0 & 0 & 0 & -4\\
      0 & 0 & 0 & -3
    \end{bmatrix}\\
    \overrightarrow{
    R_4\leftrightarrow 4R_4-3R_3}
    \begin{bmatrix}
      1 & 1 & 1 & 2\\
      0 & 1 & -2 & -1\\
      0 & 0 & 0 & -4\\
      0 & 0 & 0 & 0
    \end{bmatrix}
  \end{matrix}
\end{equation}
Come previsto dall'uguaglianza del rango per righe o per colonne, come
ottenuto che il rango della matrice è 3.\\
Si noti che, in questo caso, a dire quale vettore è combinazione degli
altri è la posizione dei pivot nella matrice ridotta: poiché questi si
trovano in prima, seconda e quarta colonna, i vettori da tenere sono il
primo, il secondi e il quarto, mentre il terzo è da ecludere (come già
sapendo dalla riduzione fatta sui vettori disposti in riga).\\
Infatti, se si segue la riduzione guardando solo le prime due colonne,
dove si trovano i primi due pivot, si vede che il rango delle matrice è
2, il che dice che i primi due vettori sono indipendenti tra loro; se
si guarda cosa succede solo alle prime tre colonne, si può notare che
il rango è ancora d2 (in quanto la teza colonna non contiene pivot) e
questo dice che il terzo vettore era allora combinazione dei primi due:
è solo aggiungendo la quarta colonna, dove si trova il terzo pivot, che
si ottiene una matrice di rango 3, il che significa che è il quarto
vettore, contrariamente al terzo, ad essere indipendente dai primi due.\\
Facendo uso della nozione di rango, possono riassumere tutto quello che
è ormai noto sulla risolubilià di un sistema e sul numero delle sue
soluzioni nel seguente risultato, detto \textit{teorema di
  Rouché-Capelli}.
\begin{teo}
  \label{teo:gauss-jordan1}
  Un sistema di $m$ equazioni lineari in $n$ incognite è compatibile se
  e solo se il rango della matrice dei coefficienti dei coefficienti è
  uguale al rango della matrice completa, e in tal caso il sistema ha
  $\infty^{n-j}$ soluzioni (dove $r$ denota il rango della matrice). In
  particolare, il sistema ha un'unica soluzione se e solo se $r=n$.
\end{teo}
\begin{proof}
  Come noto, un sistema è incompatibile se e solo se in seguito alla
  riduzione a gradini compaiono righe del tipo $
  \left(\begin{array}{ccc|c}
    0&\dots&0&b
  \end{array}\right)
  $ con $b\neq 0$.\\
  Ma questo equivale a dire che nella matrice dei coefficienti si è
  annullata una riga in più che nella matrice completa, ovvero il rango
  (che, ricordando, è il numero di righe non nulle dopo la riduzione)
  della matrice dei coefficienti è diverso (in particolare, minore) del
  rango della matrice completa. Questo dimostra la prima affermazione del
  teorema.\\
  Per quello che riguarda la seconda affermazione, si sà che una volta
  ridotto il sistema si recava la matrice incognita che compare in ogni
  equazione non nulla in funzione delle rimanenti. Se il rango della
  matrice è $r$, ci sono proprio $r$ righe non nulle e quindi si
  ricavanti, che sono $n-r$ e fungono da parametri liberi. Quindi la
  soluzione generale si scrive in funzione di $n-r$ parametri, ovvero il
  sistema ha $\infty^{n-r}$ soluzioni.\\
  L'ultima affermazione del teorema discende dal fatto che la soluzione è
  unica quando non dipende da nessun paramentro libero, ovvero $n-r=0.$
\end{proof}
\begin{oss}
  \label{oss:guess-jorda2}
  So noti che il teorema affema che hanno un'unica soluzione i sistemi
  (compatibile) in cui il numero di incognite è ugual al numero di
  equazioni a patto che queste ultime siano indipendenti.\\\\
  Prima di vedere alcune applicazioni geometriche di tutte la teoria
  dei sistemi e della riduzione vista, concludendo questa parte con due
  importanti risultati che mostrano come i sistemi omogenei hanno delle
  importanti caratteristiche che li distinguono dai sitemi in genrale:
\end{oss}
\begin{prop}
  \label{prop:gauss-jorda3}
  Dato un sistema omogeneo di $m$ equazioni in $n$ incognite a
  coefficienti in un campo $\mathds{K}$, valgono le seguenti:
  \begin{enumerate}
  \item se $s=(s_1,\dots,s_n)$ e $s^\prime=(s_1^\prime,\dots,s_n^\prime)$
    sono soluzioni del sistema, lo è anche $s+s^\prime=(s_1+s_1^\prime,
    \dots,s_n+s_n^\prime)$;
  \item se $s=(s_1,\dots,s_n)$ è una soluzone del sistema e $c\in
    \mathds{K}$, allora lo è anche $cs=(cs_1,\dots,cs_n)$
  \end{enumerate}
  In altre parole, l'insieme delle soluzioni di un sistema omogeneo in
  $n$ incognite è un sottospazio vettoriale di $\mathds{K}^n$.
\end{prop}
\begin{proof}
  Sia $a_{j1}x_1+\cdots+a_{jn}x_n=0$ la generica equazione del sistema. Il
  fatto che $s=(s_1,\dots,s_n)$ e $s^\prime=(s_1^\prime,\dots,s_n^\prime)$
  sono soluzioni del sistema significa che $a_{j1}s_1+\cdots+a_{jn}s_n=0$
  e $a_{j1}s_{1}^\prime+\cdots+a_{jn}s_n^\prime=0$. Ma allora
  \begin{equation}
    \label{eq:gauss-jorda3-1}
    \begin{matrix}
      a_{j1} (s_1+s^\prime_1) +\cdots+a_{jn}(s_n+s_n^\prime)=a_{j1}s_1^\prime+
      \cdots+a_{jn} s_n+a_{jn}s_n^\prime=\\
      =a_{j1}s_1+\cdots+a_{jn}s_1^\prime+a_{j1}s_1^\prime+\cdots+a_{jn}s_n^\prime=0+0=0
    \end{matrix}
  \end{equation}
  ovvero anche $s+s^\prime=(s_1+s_1^\prime,\dots,s_n+s_n^\prime)$ è
  soluzione: questo dimostra il primo punto.
  Per dimostrare il secondo punto invece, bisogna supporre che
  $s=(s_1,\dots,s_n)$ sia soluzione del sistama, ovvero
  $a_{j1}s_1+\cdots+a_{jn}s_n=0$ per la generica equazione, e bisogna
  osserve che
  \begin{equation}
    \label{eq:gauss-jorda3-2}
    a_{j1}cs_1+\cdots+a_{jn}cs_n=c(a_{j1}s_1+\cdots+a_{jn}s_n)=c\cdot0=0
  \end{equation}
  ovvero anche $cs=(cs_1,\cdots,cs_n)$ è soluzione, come affermato
  nel secondo punto.
\end{proof}
Nel caso di sistemi non omogenei, ovvero quelli che hanno almeno
un'equazione $a_{j1}s_1+\cdots+a_{jn}x_n=b_j$ con $b_j\neq 0$, i passaggi
visti sopra non sono più applicabili in questi casi: ad esempio, il
calcolo (\ref{eq:gauss-jorda3-1}) diventerebbe
\begin{equation*}
  \begin{matrix}
    a_{j1}(s_1+s_1^\prime)+\cdots+a_{jn}(s_n+s_n^\prime)=a_{j1}s_1+a_{j1}
    s_1^\prime+\cdots+a_{jn}s_n+a_{jn}s_n^\prime=\\
    =a_{j1}s_1+\cdots+a_{jn}s_1^\prime+\cdots+a_{jn}s_n^\prime=b_j+b_j=2b_j
  \end{matrix}
\end{equation*}
e quindi $s+s^\prime=(s_1+s_1^\prime,\dots, s_n+s_n^\prime)$ non risolve più
l'equazione $a_{j1}x_1+\cdots+a_{jn}x_n=b$ ma l'equazione $a_{j1}x_1+\cdots
+a_{jn}b_n=cb_j$ (di nuovo, chiamate diversa se $b_j=0$).\\
Quindi per i sistemi non omogenei non è possibile affermare che l'insieme
delle soluzioni `e un sottospazio vettoriale; tuttavia, vale il seguente
risultato che descrive comunque la struttura dell'insieme delle sue
soluzioni:
\end{document}
